{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first algorithm that will be implemented is the system disagreement evaluator. To this extend, to implementation are provided. The first implementation calculates the overall system disagreement level at each time step while the second implementation considers the individual disagreement levels of each predictor. \n",
    "\n",
    "The following example was portrait in the disseratation proposal:\n",
    "\n",
    "The following predictors have predicted the following values: Predictor I = 2, Predictor II = 5, Predictor III= 10. Predictor I average disagreement = $\\mathit{|2-2| + |2-5| + |2-10|} = 11/3 = 3.67$. Predictor II average disagreement = $\\mathit{|5-2| + |5-5| + |5-10|} = 8/3 = 2.67$ and finally Predictor III average disagreement = $\\mathit{|10-2| + |10-5| + |10-10|} = 13/3 = 4.33$. These values provide the systems overall disagreement level = $\\mathit{(3.67 + 2.67 + 4.33)/3} = 3.56$. \n",
    "\n",
    "At time $\\mathit{t_1}$ the final decision is compared to the real value and new weights are assigned to all predictors depending on how far off their previous prediction was from the real value. These process is repeated indefinitely and weights are adjusted accordingly at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {'Predictor I': [2, 4, 6, 6], 'Predictor II': [5, 5, 6, 5], 'Predictor III': [10, 5, 8, 8], 'Predictor IV': [2, 4, 6, 6]}\n",
    "de = {'Predictor I': [2, 4, 6, 6], 'Predictor II': [5, 5, 6, 5], 'Predictor III': [10, 5, 8, 8]}\n",
    "dg = {'Predictor I': [2, 4, 6, 6], 'Predictor II': [5, 5, 6, 5]}\n",
    "\n",
    "four = pd.DataFrame(data=d)\n",
    "three = pd.DataFrame(data=de)\n",
    "two = pd.DataFrame(data=dg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first disagreement algorithm focuses on the calculation of the overall system disagreement, at each time step, between all predictors. This implementation does not show the details of each individual predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement(data) -> list:\n",
    "    '''Takes in a DataFrame containing forecasts of different predictors and\n",
    "       calculates the disagreement score of the overall system.\n",
    "    \n",
    "        Parameters:\n",
    "            data (df): individual predictors forecast output\n",
    "        \n",
    "        Returns:\n",
    "            (df): containing overall system disagrement scores\n",
    "    '''\n",
    "    system_disagreement = []\n",
    "    for k in range(data.shape[0]):\n",
    "        individual_scores = []\n",
    "        for i in range(data.shape[1]):\n",
    "            for j in range(data.shape[1]):\n",
    "                individual_scores.append(abs(data.iloc[k,i] - data.iloc[k,j]))\n",
    "            \n",
    "        system_disagreement.append(sum(individual_scores) / len(individual_scores))\n",
    "        individual_scores.clear()\n",
    "    \n",
    "    output = pd.DataFrame()\n",
    "    output['System Disagreement'] = system_disagreement\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = disagreement(df) # 4\n",
    "test1 = disagreement(df8) #3\n",
    "test2 = disagreement(df9) #2\n",
    "\n",
    "new = disagreement(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System Disagreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   System Disagreement\n",
       "0                3.375\n",
       "1                0.500\n",
       "2                0.750\n",
       "3                1.125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second implementation of the disagreement algorithm focuses on the individual predictors disagreement level with respect to all the other algorithms. This serves to be able to further understand which algorithm contributes to what extend to the overall system disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_score(data) -> list:\n",
    "    '''Takes in a DataFrame and calculates each individual predictors disagreement\n",
    "       scores.\n",
    "    \n",
    "        Parameters:\n",
    "            data (df): individual predictors forecast output\n",
    "        \n",
    "        Returns:\n",
    "            (df): containing all predictors individual \n",
    "    '''\n",
    "    individual_score_collection = []\n",
    "    for k in range(data.shape[0]):\n",
    "        average_values = []\n",
    "        for j in range(data.shape[1]):\n",
    "            individual_scores = []\n",
    "            for i in range(data.shape[1]):\n",
    "                individual_scores.append(abs(data.iloc[k, j] - data.iloc[k, i]))\n",
    "        \n",
    "            average_values.append(sum(individual_scores) / len(individual_scores))\n",
    "            individual_scores.clear()\n",
    "            \n",
    "        individual_score_collection.append(average_values)\n",
    "    \n",
    "    return pd.DataFrame(individual_score_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = predictor_score(df)\n",
    "test2 = predictor_score(df8)\n",
    "test3 = predictor_score(df9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5.25</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3\n",
       "0  2.75  2.75  5.25  2.75\n",
       "1  0.50  0.50  0.50  0.50\n",
       "2  0.50  0.50  1.50  0.50\n",
       "3  0.75  1.25  1.75  0.75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run hello.py, this allows to import python scripts!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All weights are initialized with a value of 1. After the first real value has been observed, the error rate of each predictor is determined by taking the absolute difference between the forecast and the real value. All error rates are summed and each predictors individual error is divided by the whole error rate calculated prior. Next, from each fraction computed 1 is subtracted which yields the weights for the next forecast consensus. For example, Predictor I predicts 2, Predictor II predicts 5, Predictor III predicts 10. The consensus value is the average between these values since the initial weights are all set to 1 ($\\mathit{(2 + 5 + 10)/3 = 5.67}$). Now, if the true value at $\\mathit{t_1}$ is 6, following new weights will be assigned. First, calculate all error values: Predictor I = $\\mathit{|6-2| = 4}$, Predictor II = $\\mathit{|6 - 5| = 1}$ and Predictor III = $\\mathit{|6-10| = 4}$. The total error equals 9. Hence, the new weight assigned to Predictor I is $\\mathit{1 - (4/9) = 0.56}$, Predictor II is $\\mathit{1 - (1/9) = 0.89}$ and Predictor III is $\\mathit{1 - (4/9) = 0.56}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor I</th>\n",
       "      <th>Predictor II</th>\n",
       "      <th>Predictor III</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictor I  Predictor II  Predictor III\n",
       "0            2             5             10\n",
       "1            4             5              5\n",
       "2            6             6              8\n",
       "3            6             5              8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Predictor I': [2, 4, 6, 6], 'Predictor II': [5, 5, 6, 5], 'Predictor III': [10, 5, 8, 8]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Real Value\n",
       "0           6\n",
       "1           5\n",
       "2           6\n",
       "3           7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {'Real Value': [6, 5, 6, 7]}\n",
    "df1 = pd.DataFrame(data=d1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting(target: list) -> list:\n",
    "    '''Helper function to transform a list containing additional, unnecessary dataframe details into a pure list\n",
    "       containing only target values.\n",
    "       \n",
    "       \n",
    "        Parameters:\n",
    "            target (list): list containing unnecessary additional information\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing target values\n",
    "    '''\n",
    "    for i in range(len(target)):\n",
    "        try:\n",
    "            target[i] = target[i][0]\n",
    "        except:\n",
    "            target[i] = target[i]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(preds: list, real_value: float) -> list:\n",
    "    '''Helper function to calculated new weights, depending on t-1 forecast errors of predictors.\n",
    "    \n",
    "        Parameters:\n",
    "            preds (list): t-1 predictions of each predictor\n",
    "            real_value (float): real value at t\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing the new weight values for each predictor\n",
    "    '''\n",
    "    if type(preds) != type(list):\n",
    "        preds = list(preds)\n",
    "        \n",
    "    individual_error = []\n",
    "    new_weights = []\n",
    "    final_weights = []\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        individual_error.append(abs(preds[i] - real_value))\n",
    "    \n",
    "    total_error = sum(individual_error)\n",
    "    for j in range(len(individual_error)):\n",
    "        try:\n",
    "            if sum(total_error) == 0:\n",
    "                new_weights.append(1)\n",
    "            else:\n",
    "                new_weights.append(1-(individual_error[j]/total_error))\n",
    "        except:\n",
    "            if total_error == 0:\n",
    "                new_weights.append(1)\n",
    "            else:\n",
    "                new_weights.append(1-(individual_error[j]/total_error))\n",
    "\n",
    "        \n",
    "    for k in range(len(new_weights)):\n",
    "        final_weights.append((new_weights[k]/sum(new_weights)) * len(preds))\n",
    "    \n",
    "    return formatting(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights_correcting(preds: list, real_value: float) -> list:\n",
    "    '''Helper function to calculated new weights, depending on t-1 forecast errors of predictors.\n",
    "    \n",
    "        Parameters:\n",
    "            preds (list): t-1 predictions of each predictor\n",
    "            real_value (float): real value at t\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing the new weight values for each predictor\n",
    "    '''\n",
    "    if type(preds) != type(list):\n",
    "        preds = list(preds)\n",
    "        \n",
    "    final_weights = []\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        final_weights.append(real_value/preds[i])\n",
    "    \n",
    "    return formatting(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights_test(preds: list, real_value: float) -> list:\n",
    "    '''Helper function to calculated new weights, depending on t-1 forecast errors of predictors.\n",
    "    \n",
    "        Parameters:\n",
    "            preds (list): t-1 predictions of each predictor\n",
    "            real_value (float): real value at t\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing the new weight values for each predictor\n",
    "    '''\n",
    "    if type(preds) != type(list):\n",
    "        preds = list(preds)\n",
    "        \n",
    "    individual_error = []\n",
    "    new_weights = []\n",
    "    final_weights = []\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        individual_error.append(abs(preds[i] - real_value))\n",
    "    \n",
    "    total_error = sum(individual_error)\n",
    "    for j in range(len(individual_error)):\n",
    "        \n",
    "        if sum([total_error]) == 0:\n",
    "            new_weights.append(1)\n",
    "        else:\n",
    "            new_weights.append(1-(individual_error[j]/total_error))\n",
    "        \n",
    "\n",
    "        \n",
    "    for k in range(len(new_weights)):\n",
    "        final_weights.append((new_weights[k]/sum(new_weights)) * len(preds))\n",
    "    \n",
    "    return formatting(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights_focused(preds: list, real_value: float) -> list:\n",
    "    '''Helper function to calculated new weights, depending on t-1 forecast errors of predictors. Weights can only be 1 or 0.\n",
    "    \n",
    "        Parameters:\n",
    "            preds (list): t-1 predictions of each predictor\n",
    "            real_value (float): real value at t\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing the new weight values for each predictor\n",
    "    '''\n",
    "    if type(preds) != type(list):\n",
    "        preds = list(preds)\n",
    "        \n",
    "    individual_error = []\n",
    "    new_weights = []\n",
    "    final_weights = []\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        individual_error.append(abs(preds[i] - real_value))\n",
    "    \n",
    "    total_error = sum(individual_error)\n",
    "    for j in range(len(individual_error)):\n",
    "        if sum([total_error]) == 0: # new approach, substitutes try, except clauses. Needs testing\n",
    "            new_weights.append(1)\n",
    "        else:\n",
    "            new_weights.append(1-(individual_error[j]/total_error))\n",
    "\n",
    "    for k in range(len(new_weights)):\n",
    "        if new_weights[k] == max(new_weights):\n",
    "            final_weights.append(1)\n",
    "        else:\n",
    "            final_weights.append(0)\n",
    "    \n",
    "    return formatting(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidated_predictions_focused(data, real) -> list:\n",
    "    '''Function to calculate the consolidated prediction value of all individual predictors.\n",
    "       Takes the sole estimate of the individual predictor that best predicted in the past.\n",
    "    \n",
    "        Parameters:\n",
    "            data (df): predictions values from each individual predictor\n",
    "            real (df): actual value\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing consolidated prediction value considering new weight assignments for each predictor\n",
    "    '''\n",
    "    final_predictions = []\n",
    "    weight_history = []\n",
    "    weights = [1] * data.shape[1]\n",
    "\n",
    "    for j in range(data.shape[0]):\n",
    "        temp = []\n",
    "        for i in range(data.shape[1]):\n",
    "            temp.append(data.iloc[j, i]*weights[i])\n",
    "            \n",
    "        final_predictions.append(sum(temp)/sum(weights))\n",
    "        weight_history.append(weights)\n",
    "        weights = new_weights_focused(data.iloc[j], real.iloc[j][0])\n",
    "\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidated_predictions(data, real) -> list:\n",
    "    '''Function to calculate the consolidated prediction value of all individual predictors.\n",
    "    \n",
    "        Parameters:\n",
    "            data (df): predictions values from each individual predictor\n",
    "            real (df): actual value\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing consolidated prediction value considering new weight assignments for each predictor\n",
    "    '''\n",
    "    final_predictions = []\n",
    "    weight_history = []\n",
    "    weights = [1] * data.shape[1]\n",
    "\n",
    "    for j in range(data.shape[0]):\n",
    "        temp = []\n",
    "        for i in range(data.shape[1]):\n",
    "            temp.append(data.iloc[j, i]*weights[i])\n",
    "            \n",
    "        final_predictions.append(sum(temp)/data.shape[1])\n",
    "        weight_history.append(weights)\n",
    "        weights = new_weights_correcting(data.iloc[j], real.iloc[j][0])\n",
    "\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidated_predictions_memory(data, real) -> list:\n",
    "    '''Function to calculate the consolidated prediction value of all individual predictors. This function furthermore\n",
    "       extends consolidated_predictions by keeping a memory of prior assigned weights. An average of all prior assigned\n",
    "       weights is calculated and applied to calculate the final consolidation value.\n",
    "    \n",
    "        Parameters:\n",
    "            data (df): predictions values from each individual predictor\n",
    "            real (df): actual value\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing consolidated prediction value considering new weight assignments for each predictor\n",
    "    '''\n",
    "    final_predictions = []\n",
    "    \n",
    "    initialize = [1] * data.shape[1]\n",
    "    weight_history = [initialize]\n",
    "    weights = []\n",
    "\n",
    "    for j in range(data.shape[0]):\n",
    "        temp = []\n",
    "        for i in range(data.shape[1]):\n",
    "            temp.append(data.iloc[j, i]*([sum(z) for z in zip(*weight_history)][i]/(j+1))) # j number of rows, total value to take average\n",
    "        \n",
    "        final_predictions.append(sum(temp)/data.shape[1])\n",
    "        weights = new_weights_correcting(data.iloc[j], real.iloc[j])\n",
    "        weight_history.append(weights)\n",
    "        \n",
    "\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidated_predictions_anchor(data, real, anchor: int) -> list:\n",
    "    '''Function to calculate the consolidated prediction value of all individual predictors. To prevent the\n",
    "       algorithm from being limited to produce consolidation values within the min and max value predicted by\n",
    "       the individual predictors, min and max anchors are launched that extend above the biggest and smallest value\n",
    "       estimated.\n",
    "    \n",
    "        Parameters:\n",
    "            data (df): predictions values from each individual predictor\n",
    "            real (df): actual value\n",
    "            bojes (int): how far should max, min prediction be extended\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing consolidated prediction value considering new weight assignments for each predictor\n",
    "    '''\n",
    "    final_predictions = []\n",
    "    weight_history = []\n",
    "    \n",
    "    weights = [1] * data.shape[1]\n",
    "    weights.append(1)\n",
    "    weights.append(1)\n",
    "\n",
    "    for j in range(data.shape[0]):\n",
    "        data['Max Anchor'] = anchor * max(data.iloc[j])\n",
    "        data['Min Anchor'] = (1- (anchor - 1)) * min(data.iloc[j])\n",
    "        temp = []\n",
    "        for i in range(data.shape[1]):\n",
    "            temp.append(data.iloc[j, i]*weights[i])\n",
    "            \n",
    "        final_predictions.append(sum(temp)/data.shape[1])\n",
    "        weight_history.append(weights)\n",
    "        weights = new_weights(data.iloc[j], real.iloc[j])\n",
    "        del data['Max Anchor']\n",
    "        del data['Min Anchor']\n",
    "\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_consolidation(data) -> list:\n",
    "    '''Function to calculate simple average of all predictor forecasts.\n",
    "    \n",
    "        Parameters:\n",
    "            data (df): prediction values from each individual predictor\n",
    "        \n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            (list): list containing average values of predictor forecasts\n",
    "    '''\n",
    "    result = []\n",
    "    for i in range(data.shape[0]):\n",
    "        result.append(sum(data.iloc[i])/data.shape[1])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 4.5, 6.0, 5.5]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_consolidation(df9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.666666666666667, 4.694444444444445, 6.7407407407407405, 6.111111111111111]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated = consolidated_predictions_memory(df,df1)\n",
    "consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor I</th>\n",
       "      <th>Predictor II</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictor I  Predictor II\n",
       "0            2             5\n",
       "1            4             5\n",
       "2            6             6\n",
       "3            6             5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Real Value\n",
       "0           6\n",
       "1           5\n",
       "2           6\n",
       "3           7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 5.0, 6.0, 5.5]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidatedfocused = consolidated_predictions_focused(df9,df1)\n",
    "consolidatedfocused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1 = [2, 5, 10]\n",
    "value_2 = 6\n",
    "new_weights_focused(list_1, value_2)\n",
    "#new_weights(list_1, value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.666666666666667, 7.0, 7.166666666666667, 5.666666666666667]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_predictions(df,df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.666666666666667, 7.0, 7.166666666666667, 5.666666666666667]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_predictions(df,df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 1.2, 0.6]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1 = [2, 5, 10]\n",
    "value_2 = 6\n",
    "new_weights_correcting(list_1, value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1 = [2, 6, 6]\n",
    "value_2 = 6\n",
    "new_weights_correcting(list_1, value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real Value    6\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 9.0, 6.75, 5.5]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_predictions(two ,df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.666666666666667, 5.833333333333333, 7.944444444444444, 7.108333333333333]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_predictions_memory(three, df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_prep(input_sequence: array, sub_seq: int, steps_past: int, steps_future: int) -> array:\n",
    "    '''Prepares data input into X and y sequences. Lenght of the X sequence is dertermined by steps_past while the length of y is determined by steps_future. In detail, the predictor looks at sequence X and predicts sequence y.\n",
    "            Parameters:\n",
    "                input_sequence (array): Sequence that contains time series in array format\n",
    "                sub_seq (int): Further division of given steps a predictor will look backward.\n",
    "                steps_past (int): Steps the predictor will look backward\n",
    "                steps_future (int): Steps the predictor will look forward\n",
    "\n",
    "            Returns:\n",
    "                X (array): Array containing all looking back sequences\n",
    "                y (array): Array containing all looking forward sequences\n",
    "                modified_back (int): Modified looking back sequence length\n",
    "        '''\n",
    "    length = len(input_sequence)\n",
    "    if length == 0:\n",
    "        return (0, 0, steps_past // sub_seq)\n",
    "    X = []\n",
    "    y = []\n",
    "    if length <= steps_past:\n",
    "        raise ValueError('Input sequence is equal to or shorter than steps to look backwards')\n",
    "    if steps_future <= 0:\n",
    "        raise ValueError('Steps in the future need to be bigger than 0')\n",
    "\n",
    "    for i in range(length):\n",
    "        last = i + steps_past\n",
    "        if last > length - steps_future:\n",
    "            break\n",
    "        X.append(input_sequence[i:last])\n",
    "        y.append(input_sequence[last:last + steps_future])\n",
    "    y = array(y)\n",
    "    X = array(X)\n",
    "    modified_back = X.shape[1]//sub_seq\n",
    "    X = X.reshape((X.shape[0], sub_seq, modified_back, 1))\n",
    "    return X, y, modified_back # special treatment to account for sub sequence division\n",
    "\n",
    "test_price = np.array([28.12999916, 27.79999924, 27.79999924, 27.80999947, 27.48999977,27.70999908, 27.11000061])\n",
    "\n",
    "solution_X = np.array([[[28.12999916],\n",
    "        [27.79999924]],\n",
    "       [[27.79999924],\n",
    "        [27.79999924]],\n",
    "       [[27.79999924],\n",
    "        [27.80999947]],\n",
    "       [[27.80999947],\n",
    "        [27.48999977]],\n",
    "       [[27.48999977],\n",
    "        [27.70999908]]])\n",
    "\n",
    "solution_y = np.array([[27.79999924],\n",
    "       [27.80999947],\n",
    "       [27.48999977],\n",
    "       [27.70999908],\n",
    "       [27.11000061]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, s = sequence_prep(test_price, 2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[28.12999916]],\n",
       "\n",
       "        [[27.79999924]]],\n",
       "\n",
       "\n",
       "       [[[27.79999924]],\n",
       "\n",
       "        [[27.79999924]]],\n",
       "\n",
       "\n",
       "       [[[27.79999924]],\n",
       "\n",
       "        [[27.80999947]]],\n",
       "\n",
       "\n",
       "       [[[27.80999947]],\n",
       "\n",
       "        [[27.48999977]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.79999924, 27.80999947],\n",
       "       [27.80999947, 27.48999977],\n",
       "       [27.48999977, 27.70999908],\n",
       "       [27.70999908, 27.11000061]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
