{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":".formatting { text-align: justify; } Arguing Predictors The aim of this proof-of-concept program is to let multiple individual predictors, forecasting chaotic time series data, communicate with each other and output a consensus prediction. This project will use financial data to test the system's performance. The program is build to be easily extended. New consensus algorithms, individual predictors, evaluation methods and data import methods can be added. The System The proof-of-concept system consists of three main parts: the pre-processing pipeline, the core system and the evaluation pipeline. The Directory Structure +---arguing_predictors +---c | +---average.c | +---c_wrapper.py | +---correcting.c | +---disagreement.c | +---lib.so | +---main.c | +---prototype.h | +---test_integrate_c.py +---consensus | +---algorithms.py +---docs | +---documentation | +---... | +---mkdocs.yml +---experimental | +---predictorsX.py +---notebooks | +---System.ipynb | +---TestingEnviornment.ipynb +---pretrained | +---BI-LSTM_BP_30 | +---BI-LSTM_Ford_5 | +---BI-LSTM_SP500_40 | +---CNN-LSTM_BP_30 | +---CNN-LSTM_Ford_5 | +---CNN-LSTM_SP500_40 | +---CNN_BP_30 | +---CNN_Ford_5 | +---CNN_SP500_40 | +---LSTM_BP_30 | +---LSTM_Ford_5 | +---LSTM_SP500_40 | +---MLP_BP_30 | +---MLP_Ford_5 | +---MLP_SP500_40 +---system | +---activate.py +---test | +---test_activate.py | +---test_evaluation.py | +---test_algorithms.py | +---test_dataloader.py | +---test_predictorsI.py | +---test_predictorsII.py | +---test_predictorsIII.py +---tools | +---dataloader.py | +---evaluation.py | +---predictorsI.py | +---predictorsII.py | +---predictorsIII.py +---main.py","title":"Home"},{"location":"index.html#arguing-predictors","text":"The aim of this proof-of-concept program is to let multiple individual predictors, forecasting chaotic time series data, communicate with each other and output a consensus prediction. This project will use financial data to test the system's performance. The program is build to be easily extended. New consensus algorithms, individual predictors, evaluation methods and data import methods can be added.","title":"Arguing Predictors"},{"location":"index.html#the-system","text":"The proof-of-concept system consists of three main parts: the pre-processing pipeline, the core system and the evaluation pipeline.","title":"The System"},{"location":"index.html#the-directory-structure","text":"+---arguing_predictors +---c | +---average.c | +---c_wrapper.py | +---correcting.c | +---disagreement.c | +---lib.so | +---main.c | +---prototype.h | +---test_integrate_c.py +---consensus | +---algorithms.py +---docs | +---documentation | +---... | +---mkdocs.yml +---experimental | +---predictorsX.py +---notebooks | +---System.ipynb | +---TestingEnviornment.ipynb +---pretrained | +---BI-LSTM_BP_30 | +---BI-LSTM_Ford_5 | +---BI-LSTM_SP500_40 | +---CNN-LSTM_BP_30 | +---CNN-LSTM_Ford_5 | +---CNN-LSTM_SP500_40 | +---CNN_BP_30 | +---CNN_Ford_5 | +---CNN_SP500_40 | +---LSTM_BP_30 | +---LSTM_Ford_5 | +---LSTM_SP500_40 | +---MLP_BP_30 | +---MLP_Ford_5 | +---MLP_SP500_40 +---system | +---activate.py +---test | +---test_activate.py | +---test_evaluation.py | +---test_algorithms.py | +---test_dataloader.py | +---test_predictorsI.py | +---test_predictorsII.py | +---test_predictorsIII.py +---tools | +---dataloader.py | +---evaluation.py | +---predictorsI.py | +---predictorsII.py | +---predictorsIII.py +---main.py","title":"The Directory Structure"},{"location":"consensus.html","text":".formatting { text-align: justify; } Consensus Algorithms The algorithms.py file can be located in the consensus directory which houses all algorithms that determine the final systems consensus prediction. The systems current version contains in total the following 7 consensus algorithms and 2 disagreement algorithms: Disagreement algorithms: System disagreement Predictor score Consensus algorithms: No Memory Memory Focus Correcting Correcting Memory Anchor Average More algorithms can be easily added by following the examples shown in the file below. algorithms.py Disagreement algorithms import pandas as pd from pandas import DataFrame def disagreement ( data : DataFrame ) -> DataFrame : '''Takes in a DataFrame containing forecasts of different predictors and calculates the disagreement score of the overall system. Parameters: data (DataFrame): Individual predictors forecast output. Returns: (DataFrame): Containing overall system disagreement scores. ''' system_disagreement = [] for k in range ( data . shape [ 0 ]): individual_scores = [] for i in range ( data . shape [ 1 ]): for j in range ( data . shape [ 1 ]): individual_scores . append ( abs ( data . iloc [ k , i ] - data . iloc [ k , j ])) # absolute difference between each possible individual predictor pair system_disagreement . append ( sum ( individual_scores ) / len ( individual_scores )) # average of all individual scores individual_scores . clear () output = pd . DataFrame () output [ 'System Disagreement' ] = system_disagreement return output def predictor_score ( data : DataFrame ) -> DataFrame : '''Takes in a DataFrame and calculates each individual predictors disagreement scores. Parameters: data (DataFrame): Individual predictors forecast output. Returns: (DataFrame): Containing all predictors individual. ''' individual_score_collection = [] for k in range ( data . shape [ 0 ]): average_values = [] # collecting each individual predictors average disagreement value with other predictors for j in range ( data . shape [ 1 ]): individual_scores = [] # collecting each individual predictors disagreement value with other predictors for i in range ( data . shape [ 1 ]): individual_scores . append ( abs ( data . iloc [ k , j ] - data . iloc [ k , i ])) average_values . append ( sum ( individual_scores ) / len ( individual_scores )) individual_scores . clear () individual_score_collection . append ( average_values ) result = pd . DataFrame ( individual_score_collection ) result . columns = data . columns # custom made columns for each predictor disagreement result = result . add_suffix ( ' disagreement score' ) return result The function below serves as a helper function to ensure correct formatting after the weight calculation functions have been applied. def formatting ( target : list ) -> list : '''Helper function to transform a list containing additional, unnecessary data frame details into a pure list containing only target values. Parameters: target (list): List containing unnecessary additional information. Returns: (list): List containing target values. ''' for i in range ( len ( target )): try : target [ i ] = target [ i ][ 0 ] # unpacking numerical values except : target [ i ] = target [ i ] # if nothing to unpack return target Weight calculations The most common pattern of the consensus algorithms contained in this file is to divide the final consensus value calculation into a weight calculation step and a final consensus value calculation step. The next code snippets show how the weight values are calculated in the different consensus algorithms. Memory and No-memory weight calculation: def new_weights ( preds : list , real_value : float ) -> list : '''Helper function to calculated new weights, depending on t-1 forecast errors of predictors. Parameters: preds (list): t-1 predictions of each predictor. real_value (float): Real value at time t. Returns: (list): List containing the new weight values for each predictor. ''' if type ( preds ) != type ( list ): preds = list ( preds ) # if input not a list, transformation into list individual_error = [] new_weights = [] final_weights = [] for i in range ( len ( preds )): individual_error . append ( abs ( preds [ i ] - real_value )) total_error = sum ( individual_error ) for j in range ( len ( individual_error )): if sum ([ total_error ]) == 0 : # no error, assign full weight new_weights . append ( 1 ) else : new_weights . append ( 1 - ( individual_error [ j ] / total_error )) for k in range ( len ( new_weights )): final_weights . append (( new_weights [ k ] / sum ( new_weights )) * len ( preds )) return formatting ( final_weights ) Focus weight calculation: def new_weights_focused ( preds : list , real_value : float ) -> list : '''Helper function to calculated new weights, depending on t-1 forecast errors of predictors. Weights can only be 1 or 0. Parameters: preds (list): t-1 predictions of each predictor. real_value (float): Real value at time t. Returns: (list): List containing the new weight values for each predictor. ''' if type ( preds ) != type ( list ): preds = list ( preds ) individual_error = [] new_weights = [] final_weights = [] for i in range ( len ( preds )): individual_error . append ( abs ( preds [ i ] - real_value )) total_error = sum ( individual_error ) for j in range ( len ( individual_error )): if sum ([ total_error ]) == 0 : new_weights . append ( 1 ) else : new_weights . append ( 1 - ( individual_error [ j ] / total_error )) for k in range ( len ( new_weights )): if new_weights [ k ] == max ( new_weights ): final_weights . append ( 1 ) # assign weight of 1 to best predictor else : final_weights . append ( 0 ) # assign weight of 0 to worst predictors return formatting ( final_weights ) Correcting and Correcting-memory weight calculation: def new_weights_correcting ( preds : list , real_value : float ) -> list : '''Helper function to calculated forced correction weights based on t - 1 error. Parameters: preds (list): t-1 predictions of each predictor real_value (float): real value at t Returns: (list): list containing the new weight values for each predictor ''' if type ( preds ) != type ( list ): preds = list ( preds ) final_weights = [] for i in range ( len ( preds )): final_weights . append ( real_value / preds [ i ]) # weight = prediction error correction value return formatting ( final_weights ) Consolidation value calculation No-memory consensus algorithm: def consolidated_predictions ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual values. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] weight_history = [] weights = [ 1 ] * data . shape [ 1 ] for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * weights [ i ]) final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) # take average of all weight corrected predictor forecasts weight_history . append ( weights ) # collecting all weights assigned in the past, mostly for debugging weights = new_weights ( data . iloc [ j ], real . iloc [ j ][ 0 ]) # calculate new weights return final_predictions Memory consensus algorithm: def consolidated_predictions_memory ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. This function furthermore extends consolidated_predictions by keeping a memory of prior assigned weights. An average of all prior assigned weights is calculated and applied to calculate the final consolidation value. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual value. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] initialize = [ 1 ] * data . shape [ 1 ] weight_history = [ initialize ] # initialize weight history with 1 values weights = [] for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * ([ sum ( z ) for z in zip ( * weight_history )][ i ] / ( j + 1 ))) # j number of rows, total value to take average; using weight history to compute average values of weights final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) weights = new_weights ( data . iloc [ j ], real . iloc [ j ][ 0 ]) weight_history . append ( weights ) return final_predictions Focused consensus algorithm: def consolidated_predictions_focused ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. Takes the sole estimate of the individual predictor that best predicted in the past. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual value. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] weight_history = [] weights = [ 1 ] * data . shape [ 1 ] # initial weights are set to 1 for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * weights [ i ]) final_predictions . append ( sum ( temp ) / sum ( weights )) weight_history . append ( weights ) weights = new_weights_focused ( data . iloc [ j ], real . iloc [ j ][ 0 ]) return final_predictions Correcting consensus algorithm: def consolidated_predictions_correcting ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual values. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] weight_history = [] weights = [ 1 ] * data . shape [ 1 ] for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * weights [ i ]) final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) weight_history . append ( weights ) weights = new_weights_correcting ( data . iloc [ j ], real . iloc [ j ][ 0 ]) return final_predictions Correcting-memory consensus algorithm: def consolidated_predictions_memory_correcting ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. This function furthermore extends consolidated_predictions by keeping a memory of prior assigned weights. An average of all prior assigned weights is calculated and applied to calculate the final consolidation value. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual value. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] initialize = [ 1 ] * data . shape [ 1 ] weight_history = [ initialize ] weights = [] for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * ([ sum ( z ) for z in zip ( * weight_history )][ i ] / ( j + 1 ))) # j number of rows, total value to take average final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) weights = new_weights_correcting ( data . iloc [ j ], real . iloc [ j ][ 0 ]) weight_history . append ( weights ) return final_predictions Anchor consensus algorithm: def consolidated_predictions_anchor ( data : DataFrame , real : DataFrame , anchor : int ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. To prevent the algorithm from being limited to produce consolidation values within the min and max value predicted by the individual predictors, min and max anchors are launched that extend above the biggest and smallest value estimated. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual value. anchor (int): How far should max, min prediction be extended. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' if anchor <= 1 : raise ValueError ( 'Anchors need to be set at least > 1' ) final_predictions = [] weight_history = [] weights = [ 1 ] * data . shape [ 1 ] weights . append ( 1 ) weights . append ( 1 ) for j in range ( data . shape [ 0 ]): data [ 'Max Anchor' ] = anchor * max ( data . iloc [ j ]) # creating maximum anchor data [ 'Min Anchor' ] = ( 1 - ( anchor - 1 )) * min ( data . iloc [ j ]) # creating minimum anchor temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * weights [ i ]) final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) weight_history . append ( weights ) weights = new_weights ( data . iloc [ j ], real . iloc [ j ][ 0 ]) del data [ 'Max Anchor' ] # delete maximum anchor del data [ 'Min Anchor' ] # delete minimum anchor return final_predictions Average consensus algorithm: def average_consolidation ( data : DataFrame ) -> list : '''Function to calculate simple average of all predictor forecasts. Parameters: data (DataFrame): Prediction values from each individual predictor. Returns: (list): List containing average values of predictor forecasts. ''' result = [] for i in range ( data . shape [ 0 ]): result . append ( sum ( data . iloc [ i ]) / data . shape [ 1 ]) # simple average of all individual predictors forecasts return result","title":"Consensus"},{"location":"consensus.html#consensus-algorithms","text":"The algorithms.py file can be located in the consensus directory which houses all algorithms that determine the final systems consensus prediction. The systems current version contains in total the following 7 consensus algorithms and 2 disagreement algorithms: Disagreement algorithms: System disagreement Predictor score Consensus algorithms: No Memory Memory Focus Correcting Correcting Memory Anchor Average More algorithms can be easily added by following the examples shown in the file below.","title":"Consensus Algorithms"},{"location":"consensus.html#algorithmspy","text":"","title":"algorithms.py"},{"location":"consensus.html#disagreement-algorithms","text":"import pandas as pd from pandas import DataFrame def disagreement ( data : DataFrame ) -> DataFrame : '''Takes in a DataFrame containing forecasts of different predictors and calculates the disagreement score of the overall system. Parameters: data (DataFrame): Individual predictors forecast output. Returns: (DataFrame): Containing overall system disagreement scores. ''' system_disagreement = [] for k in range ( data . shape [ 0 ]): individual_scores = [] for i in range ( data . shape [ 1 ]): for j in range ( data . shape [ 1 ]): individual_scores . append ( abs ( data . iloc [ k , i ] - data . iloc [ k , j ])) # absolute difference between each possible individual predictor pair system_disagreement . append ( sum ( individual_scores ) / len ( individual_scores )) # average of all individual scores individual_scores . clear () output = pd . DataFrame () output [ 'System Disagreement' ] = system_disagreement return output def predictor_score ( data : DataFrame ) -> DataFrame : '''Takes in a DataFrame and calculates each individual predictors disagreement scores. Parameters: data (DataFrame): Individual predictors forecast output. Returns: (DataFrame): Containing all predictors individual. ''' individual_score_collection = [] for k in range ( data . shape [ 0 ]): average_values = [] # collecting each individual predictors average disagreement value with other predictors for j in range ( data . shape [ 1 ]): individual_scores = [] # collecting each individual predictors disagreement value with other predictors for i in range ( data . shape [ 1 ]): individual_scores . append ( abs ( data . iloc [ k , j ] - data . iloc [ k , i ])) average_values . append ( sum ( individual_scores ) / len ( individual_scores )) individual_scores . clear () individual_score_collection . append ( average_values ) result = pd . DataFrame ( individual_score_collection ) result . columns = data . columns # custom made columns for each predictor disagreement result = result . add_suffix ( ' disagreement score' ) return result The function below serves as a helper function to ensure correct formatting after the weight calculation functions have been applied. def formatting ( target : list ) -> list : '''Helper function to transform a list containing additional, unnecessary data frame details into a pure list containing only target values. Parameters: target (list): List containing unnecessary additional information. Returns: (list): List containing target values. ''' for i in range ( len ( target )): try : target [ i ] = target [ i ][ 0 ] # unpacking numerical values except : target [ i ] = target [ i ] # if nothing to unpack return target","title":"Disagreement algorithms"},{"location":"consensus.html#weight-calculations","text":"The most common pattern of the consensus algorithms contained in this file is to divide the final consensus value calculation into a weight calculation step and a final consensus value calculation step. The next code snippets show how the weight values are calculated in the different consensus algorithms. Memory and No-memory weight calculation: def new_weights ( preds : list , real_value : float ) -> list : '''Helper function to calculated new weights, depending on t-1 forecast errors of predictors. Parameters: preds (list): t-1 predictions of each predictor. real_value (float): Real value at time t. Returns: (list): List containing the new weight values for each predictor. ''' if type ( preds ) != type ( list ): preds = list ( preds ) # if input not a list, transformation into list individual_error = [] new_weights = [] final_weights = [] for i in range ( len ( preds )): individual_error . append ( abs ( preds [ i ] - real_value )) total_error = sum ( individual_error ) for j in range ( len ( individual_error )): if sum ([ total_error ]) == 0 : # no error, assign full weight new_weights . append ( 1 ) else : new_weights . append ( 1 - ( individual_error [ j ] / total_error )) for k in range ( len ( new_weights )): final_weights . append (( new_weights [ k ] / sum ( new_weights )) * len ( preds )) return formatting ( final_weights ) Focus weight calculation: def new_weights_focused ( preds : list , real_value : float ) -> list : '''Helper function to calculated new weights, depending on t-1 forecast errors of predictors. Weights can only be 1 or 0. Parameters: preds (list): t-1 predictions of each predictor. real_value (float): Real value at time t. Returns: (list): List containing the new weight values for each predictor. ''' if type ( preds ) != type ( list ): preds = list ( preds ) individual_error = [] new_weights = [] final_weights = [] for i in range ( len ( preds )): individual_error . append ( abs ( preds [ i ] - real_value )) total_error = sum ( individual_error ) for j in range ( len ( individual_error )): if sum ([ total_error ]) == 0 : new_weights . append ( 1 ) else : new_weights . append ( 1 - ( individual_error [ j ] / total_error )) for k in range ( len ( new_weights )): if new_weights [ k ] == max ( new_weights ): final_weights . append ( 1 ) # assign weight of 1 to best predictor else : final_weights . append ( 0 ) # assign weight of 0 to worst predictors return formatting ( final_weights ) Correcting and Correcting-memory weight calculation: def new_weights_correcting ( preds : list , real_value : float ) -> list : '''Helper function to calculated forced correction weights based on t - 1 error. Parameters: preds (list): t-1 predictions of each predictor real_value (float): real value at t Returns: (list): list containing the new weight values for each predictor ''' if type ( preds ) != type ( list ): preds = list ( preds ) final_weights = [] for i in range ( len ( preds )): final_weights . append ( real_value / preds [ i ]) # weight = prediction error correction value return formatting ( final_weights )","title":"Weight calculations"},{"location":"consensus.html#consolidation-value-calculation","text":"No-memory consensus algorithm: def consolidated_predictions ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual values. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] weight_history = [] weights = [ 1 ] * data . shape [ 1 ] for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * weights [ i ]) final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) # take average of all weight corrected predictor forecasts weight_history . append ( weights ) # collecting all weights assigned in the past, mostly for debugging weights = new_weights ( data . iloc [ j ], real . iloc [ j ][ 0 ]) # calculate new weights return final_predictions Memory consensus algorithm: def consolidated_predictions_memory ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. This function furthermore extends consolidated_predictions by keeping a memory of prior assigned weights. An average of all prior assigned weights is calculated and applied to calculate the final consolidation value. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual value. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] initialize = [ 1 ] * data . shape [ 1 ] weight_history = [ initialize ] # initialize weight history with 1 values weights = [] for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * ([ sum ( z ) for z in zip ( * weight_history )][ i ] / ( j + 1 ))) # j number of rows, total value to take average; using weight history to compute average values of weights final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) weights = new_weights ( data . iloc [ j ], real . iloc [ j ][ 0 ]) weight_history . append ( weights ) return final_predictions Focused consensus algorithm: def consolidated_predictions_focused ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. Takes the sole estimate of the individual predictor that best predicted in the past. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual value. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] weight_history = [] weights = [ 1 ] * data . shape [ 1 ] # initial weights are set to 1 for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * weights [ i ]) final_predictions . append ( sum ( temp ) / sum ( weights )) weight_history . append ( weights ) weights = new_weights_focused ( data . iloc [ j ], real . iloc [ j ][ 0 ]) return final_predictions Correcting consensus algorithm: def consolidated_predictions_correcting ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual values. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] weight_history = [] weights = [ 1 ] * data . shape [ 1 ] for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * weights [ i ]) final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) weight_history . append ( weights ) weights = new_weights_correcting ( data . iloc [ j ], real . iloc [ j ][ 0 ]) return final_predictions Correcting-memory consensus algorithm: def consolidated_predictions_memory_correcting ( data : DataFrame , real : DataFrame ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. This function furthermore extends consolidated_predictions by keeping a memory of prior assigned weights. An average of all prior assigned weights is calculated and applied to calculate the final consolidation value. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual value. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' final_predictions = [] initialize = [ 1 ] * data . shape [ 1 ] weight_history = [ initialize ] weights = [] for j in range ( data . shape [ 0 ]): temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * ([ sum ( z ) for z in zip ( * weight_history )][ i ] / ( j + 1 ))) # j number of rows, total value to take average final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) weights = new_weights_correcting ( data . iloc [ j ], real . iloc [ j ][ 0 ]) weight_history . append ( weights ) return final_predictions Anchor consensus algorithm: def consolidated_predictions_anchor ( data : DataFrame , real : DataFrame , anchor : int ) -> list : '''Function to calculate the consolidated prediction value of all individual predictors. To prevent the algorithm from being limited to produce consolidation values within the min and max value predicted by the individual predictors, min and max anchors are launched that extend above the biggest and smallest value estimated. Parameters: data (DataFrame): Predictions values from each individual predictor. real (DataFrame): Actual value. anchor (int): How far should max, min prediction be extended. Returns: (list): List containing consolidated prediction value considering new weight assignments for each predictor. ''' if anchor <= 1 : raise ValueError ( 'Anchors need to be set at least > 1' ) final_predictions = [] weight_history = [] weights = [ 1 ] * data . shape [ 1 ] weights . append ( 1 ) weights . append ( 1 ) for j in range ( data . shape [ 0 ]): data [ 'Max Anchor' ] = anchor * max ( data . iloc [ j ]) # creating maximum anchor data [ 'Min Anchor' ] = ( 1 - ( anchor - 1 )) * min ( data . iloc [ j ]) # creating minimum anchor temp = [] for i in range ( data . shape [ 1 ]): temp . append ( data . iloc [ j , i ] * weights [ i ]) final_predictions . append ( sum ( temp ) / data . shape [ 1 ]) weight_history . append ( weights ) weights = new_weights ( data . iloc [ j ], real . iloc [ j ][ 0 ]) del data [ 'Max Anchor' ] # delete maximum anchor del data [ 'Min Anchor' ] # delete minimum anchor return final_predictions Average consensus algorithm: def average_consolidation ( data : DataFrame ) -> list : '''Function to calculate simple average of all predictor forecasts. Parameters: data (DataFrame): Prediction values from each individual predictor. Returns: (list): List containing average values of predictor forecasts. ''' result = [] for i in range ( data . shape [ 0 ]): result . append ( sum ( data . iloc [ i ]) / data . shape [ 1 ]) # simple average of all individual predictors forecasts return result","title":"Consolidation value calculation"},{"location":"evaluation.html","text":".formatting { text-align: justify; } Evaluation Importing libraries It is recommended to use already implemented metrics from libraries such as Scikit-learn.org. More metrics for regression evaluation can be found on the Scikit-learn.org documentation page here . import pandas as pd from pandas import DataFrame import seaborn as sns import matplotlib.pyplot as plt import sys sys . path . append ( '../' ) from consensus.algorithms import disagreement , predictor_score # since disagreement scores are used in this evaluation pipeline set-up from sklearn.metrics import mean_squared_error from sklearn.metrics import mean_absolute_error from sklearn.metrics import mean_squared_log_error Data summary generation The following functions are used to collect all in the prior generated data and summarize them into one data frame. It also supports the functionality of generating a correlation matrix of the summarized data. def set_same_index ( to_df : DataFrame , from_df : DataFrame ) -> DataFrame : '''Helper function to transfer the dates of a date-time indexed dataframe to another. Parameter: to_df (DataFrame): Target DataFrame, application destination. from_df (DataFrame): DataFrame containing date-time index. Returns: (DataFrame): Target DataFrame with date-time index. ''' to_df = to_df . set_index ( from_df . index ) return to_df def evaluation_frame ( to_df : DataFrame , from_df : DataFrame ) -> DataFrame : '''Helper function to transfer the dates of a date-time indexed dataframe to another while additionally attaching the Real Value column. Parameters: to_df (DataFrame): Target DataFrame, application destination. from_df (DataFrame): DataFrame containing date-time index and Real Value column. Returns: (DataFrame): Target DataFrame with date-time index and Real Valeu column. ''' to_df = to_df . set_index ( from_df . index ) to_df [ 'Real Value' ] = from_df return to_df def combined_frame ( df1 : DataFrame , df2 : DataFrame , real : DataFrame ) -> DataFrame : '''Combining the individual predictors forecast DataFrame with the algorithm consensus values DataFrame. These two DataFrames are divided by the Real Value column. Parameters: df1 (DataFrame): First DataFrame, for example: DataFrame containing algorithms consensus values. df2 (DataFrame): Second DataFrame, for example: DataFrame containing individual predictors forecasts. real (DataFrame): DataFrame containing the real values. Returns: (DataFrame): Combined DataFrame with Real Value column in the middle. ''' df1 = set_same_index ( df1 , real ) df2 = evaluation_frame ( df2 , real ) combined_frame = pd . concat ([ df2 , df1 ], axis = 1 ) return combined_frame def all_stats_frame ( combined : DataFrame , predictor_forecasts : DataFrame ) -> DataFrame : '''Combining the combined DataFrame with disagreement statistics to build a DataFrame containing all system statistics. Parameters: combined (DataFrame): First DataFrame, containing algorithms, consensus and real value. predictor_forecasts (DataFrame): DataFrame containing predictor forecasts. Returns: (DataFrame): DataFrame containing all system statistics. ''' dis = disagreement ( predictor_forecasts ) score = predictor_score ( predictor_forecasts ) adjusted_dis = set_same_index ( dis , combined ) adjusted_score = set_same_index ( score , combined ) result = pd . concat ([ combined , adjusted_dis , adjusted_score ], axis = 1 ) return result def correlation ( df : DataFrame , plot : bool = False ) -> DataFrame : '''Computation of correlation matrix with Pandas Library corr() function. Parameters: df (DataFrame): DataFrame to supply data for the correlation matrix. plot (bool): Option to plot correlation heatmap when True is passed in. Returns: (DataFrame): Correlation matrix of supplied DataFrame. ''' corr_matrix = df . corr () if plot == True : plt . figure ( figsize = ( 15 , 15 )) sns . heatmap ( corr_matrix , annot = True ) return corr_matrix def absolute_error_analytics ( predictors : DataFrame , algorithms : DataFrame , real : DataFrame ) -> DataFrame : '''Computes the absolute error values of all individual predictors and consensus algorithms. Additionally adds system disagreement and individual predictors disagreement scores. Parameters: predictors (DataFrame): DataFrame containing individual predictors forecasts. algorithms (DataFrame): DataFrame containing consensus algorithm forecasts. real (DataFrame): DataFrame containing actual future values. Returns: (DataFrame): DataFrame containing all absolute error values of individual predictors and consensus algorithms together with system disagreement and individual disagreement scores. ''' data = evaluation_frame ( predictors , real ) data2 = evaluation_frame ( algorithms , real ) individual_disagreements = predictor_score ( predictors ) individual_disagreements = set_same_index ( individual_disagreements , real ) system_disagreement = disagreement ( predictors ) system_disagreement = set_same_index ( system_disagreement , real ) result = pd . DataFrame () for i in range ( len ( data . columns ) - 1 ): # do not include Real value column current_column = data . columns [ i ] result [ current_column + ' absolute error' ] = abs ( data [ current_column ] - data [ 'Real Value' ]) for i in range ( len ( data2 . columns ) - 1 ): current_column = data2 . columns [ i ] result [ current_column + ' absolute error' ] = abs ( data2 [ current_column ] - data2 [ 'Real Value' ]) result = pd . concat ([ result , individual_disagreements , system_disagreement ], axis = 1 ) return result Evaluation Metrics The following functions apply different regression metrices onto the forecasted data. More, metrics can be added using the same template. Further regression metrices can be important from the Scikit-learn python library here . def mse_score ( df : DataFrame , plot : bool = False ) -> DataFrame : '''Calculates the mean squared error for the individual predictors and consensus algorithms. Option to plot MSE performances in descending order. Parameters: df (DataFrame): DataFrame containing individual predictors forecasts and consensus values of algorithms. plot (bool): Option to plot MSE performance chart. Returns: (DataFrame): DataFrame containing mean squared error of individual predictors forecasts and consensus values of algorithms. ''' # finding start and end index since Real Value column is in the middle end = ( list ( df . columns ) . index ( 'Real Value' )) start = ( list ( df . columns ) . index ( 'Real Value' )) + 1 y_true = df [ 'Real Value' ] name = [] mse = [] for i in range ( 0 , end ): name . append ( df . columns [ i ]) mse . append ( mean_squared_error ( y_true , df . iloc [:, i ])) for i in range ( start , df . shape [ 1 ]): name . append ( df . columns [ i ]) mse . append ( mean_squared_error ( y_true , df . iloc [:, i ])) data = { 'Algorithms' : name , 'MSE' : mse } result = pd . DataFrame ( data ) if plot == True : # plotting results if set to True to_plot = result . sort_values ( by = 'MSE' ) to_plot . plot . bar ( x = 'Algorithms' , y = 'MSE' , figsize = ( 15 , 6 )) return result def mae_score ( df : DataFrame , plot : bool = False ) -> DataFrame : '''Calculates the mean absolute error for the individual predictors and consensus algorithms. Option to plot MAE performances in descending order. Parameters: df (DataFrame): DataFrame containing individual predictors forecasts and consensus values of algorithms. plot (bool): Option to plot MAE performance chart. Returns: (DataFrame): DataFrame containing mean absolute error of individual predictors forecasts and consensus values of algorithms. ''' end = ( list ( df . columns ) . index ( 'Real Value' )) start = ( list ( df . columns ) . index ( 'Real Value' )) + 1 y_true = df [ 'Real Value' ] name = [] mae = [] for i in range ( 0 , end ): name . append ( df . columns [ i ]) mae . append ( mean_absolute_error ( y_true , df . iloc [:, i ])) for i in range ( start , df . shape [ 1 ]): name . append ( df . columns [ i ]) mae . append ( mean_absolute_error ( y_true , df . iloc [:, i ])) data = { 'Algorithms' : name , 'MAE' : mae } result = pd . DataFrame ( data ) if plot == True : to_plot = result . sort_values ( by = 'MAE' ) to_plot . plot . bar ( x = 'Algorithms' , y = 'MAE' , figsize = ( 15 , 6 )) return result def mse_log_score ( df : DataFrame , plot : bool = False ) -> DataFrame : '''Calculates the mean squared log error for the individual predictors and consensus algorithms. Option to plot MSE log performances in descending order. Parameters: df (DataFrame): DataFrame containing individual predictors forecasts and consensus values of algorithms. plot (bool): Option to plot MSE log performance chart. Returns: (DataFrame): DataFrame containing mean squared log error of individual predictors forecasts and consensus values of algorithms. ''' end = ( list ( df . columns ) . index ( 'Real Value' )) start = ( list ( df . columns ) . index ( 'Real Value' )) + 1 y_true = df [ 'Real Value' ] name = [] mse_log = [] for i in range ( 0 , end ): name . append ( df . columns [ i ]) mse_log . append ( mean_squared_log_error ( y_true , df . iloc [:, i ])) for i in range ( start , df . shape [ 1 ]): name . append ( df . columns [ i ]) mse_log . append ( mean_squared_log_error ( y_true , df . iloc [:, i ])) data = { 'Algorithms' : name , 'MSE Log' : mse_log } result = pd . DataFrame ( data ) if plot == True : to_plot = result . sort_values ( by = 'MSE Log' ) to_plot . plot . bar ( x = 'Algorithms' , y = 'MSE Log' , figsize = ( 15 , 6 )) return result Plotting The last part of the activate.py file plots all predictions vs the real values: def plot_performance ( data : DataFrame ): '''Plots individual predictors forecasts and consensus values of algorithms against the real values. Parameters: data (DataFrame): DataFrame containing individual predictors forecasts, consensus values and real values. ''' columns = data . columns for i in range ( len ( columns )): if columns [ i ] == 'Real Value' : continue abs_error = abs ( data [ columns [ i ]] - data [ 'Real Value' ]) # absolute error between real and predicted values (subplot) fig , ax = plt . subplots ( 2 , 1 , figsize = ( 15 , 6 )) ax [ 0 ] . plot ( data [ 'Real Value' ]) ax [ 0 ] . plot ( data [ columns [ i ]]) ax [ 0 ] . title . set_text ( columns [ i ] + ' Algorithm Error' ) ax [ 0 ] . set_ylabel ( 'Stock Price' ) ax [ 0 ] . set_xlabel ( 'Time' ) ax [ 0 ] . legend ([ 'Real Value' , 'Prediction' ], loc = 'upper right' ) ax [ 1 ] . plot ( abs_error , 'r' ) ax [ 1 ] . title . set_text ( columns [ i ] + ' Absolute Error' ) ax [ 1 ] . set_ylabel ( 'Error' ) ax [ 1 ] . set_xlabel ( 'Time' ) ax [ 1 ] . legend ([ 'Error' ], loc = 'upper right' ) plt . tight_layout ()","title":"Evaluation"},{"location":"evaluation.html#evaluation","text":"","title":"Evaluation"},{"location":"evaluation.html#importing-libraries","text":"It is recommended to use already implemented metrics from libraries such as Scikit-learn.org. More metrics for regression evaluation can be found on the Scikit-learn.org documentation page here . import pandas as pd from pandas import DataFrame import seaborn as sns import matplotlib.pyplot as plt import sys sys . path . append ( '../' ) from consensus.algorithms import disagreement , predictor_score # since disagreement scores are used in this evaluation pipeline set-up from sklearn.metrics import mean_squared_error from sklearn.metrics import mean_absolute_error from sklearn.metrics import mean_squared_log_error","title":"Importing libraries"},{"location":"evaluation.html#data-summary-generation","text":"The following functions are used to collect all in the prior generated data and summarize them into one data frame. It also supports the functionality of generating a correlation matrix of the summarized data. def set_same_index ( to_df : DataFrame , from_df : DataFrame ) -> DataFrame : '''Helper function to transfer the dates of a date-time indexed dataframe to another. Parameter: to_df (DataFrame): Target DataFrame, application destination. from_df (DataFrame): DataFrame containing date-time index. Returns: (DataFrame): Target DataFrame with date-time index. ''' to_df = to_df . set_index ( from_df . index ) return to_df def evaluation_frame ( to_df : DataFrame , from_df : DataFrame ) -> DataFrame : '''Helper function to transfer the dates of a date-time indexed dataframe to another while additionally attaching the Real Value column. Parameters: to_df (DataFrame): Target DataFrame, application destination. from_df (DataFrame): DataFrame containing date-time index and Real Value column. Returns: (DataFrame): Target DataFrame with date-time index and Real Valeu column. ''' to_df = to_df . set_index ( from_df . index ) to_df [ 'Real Value' ] = from_df return to_df def combined_frame ( df1 : DataFrame , df2 : DataFrame , real : DataFrame ) -> DataFrame : '''Combining the individual predictors forecast DataFrame with the algorithm consensus values DataFrame. These two DataFrames are divided by the Real Value column. Parameters: df1 (DataFrame): First DataFrame, for example: DataFrame containing algorithms consensus values. df2 (DataFrame): Second DataFrame, for example: DataFrame containing individual predictors forecasts. real (DataFrame): DataFrame containing the real values. Returns: (DataFrame): Combined DataFrame with Real Value column in the middle. ''' df1 = set_same_index ( df1 , real ) df2 = evaluation_frame ( df2 , real ) combined_frame = pd . concat ([ df2 , df1 ], axis = 1 ) return combined_frame def all_stats_frame ( combined : DataFrame , predictor_forecasts : DataFrame ) -> DataFrame : '''Combining the combined DataFrame with disagreement statistics to build a DataFrame containing all system statistics. Parameters: combined (DataFrame): First DataFrame, containing algorithms, consensus and real value. predictor_forecasts (DataFrame): DataFrame containing predictor forecasts. Returns: (DataFrame): DataFrame containing all system statistics. ''' dis = disagreement ( predictor_forecasts ) score = predictor_score ( predictor_forecasts ) adjusted_dis = set_same_index ( dis , combined ) adjusted_score = set_same_index ( score , combined ) result = pd . concat ([ combined , adjusted_dis , adjusted_score ], axis = 1 ) return result def correlation ( df : DataFrame , plot : bool = False ) -> DataFrame : '''Computation of correlation matrix with Pandas Library corr() function. Parameters: df (DataFrame): DataFrame to supply data for the correlation matrix. plot (bool): Option to plot correlation heatmap when True is passed in. Returns: (DataFrame): Correlation matrix of supplied DataFrame. ''' corr_matrix = df . corr () if plot == True : plt . figure ( figsize = ( 15 , 15 )) sns . heatmap ( corr_matrix , annot = True ) return corr_matrix def absolute_error_analytics ( predictors : DataFrame , algorithms : DataFrame , real : DataFrame ) -> DataFrame : '''Computes the absolute error values of all individual predictors and consensus algorithms. Additionally adds system disagreement and individual predictors disagreement scores. Parameters: predictors (DataFrame): DataFrame containing individual predictors forecasts. algorithms (DataFrame): DataFrame containing consensus algorithm forecasts. real (DataFrame): DataFrame containing actual future values. Returns: (DataFrame): DataFrame containing all absolute error values of individual predictors and consensus algorithms together with system disagreement and individual disagreement scores. ''' data = evaluation_frame ( predictors , real ) data2 = evaluation_frame ( algorithms , real ) individual_disagreements = predictor_score ( predictors ) individual_disagreements = set_same_index ( individual_disagreements , real ) system_disagreement = disagreement ( predictors ) system_disagreement = set_same_index ( system_disagreement , real ) result = pd . DataFrame () for i in range ( len ( data . columns ) - 1 ): # do not include Real value column current_column = data . columns [ i ] result [ current_column + ' absolute error' ] = abs ( data [ current_column ] - data [ 'Real Value' ]) for i in range ( len ( data2 . columns ) - 1 ): current_column = data2 . columns [ i ] result [ current_column + ' absolute error' ] = abs ( data2 [ current_column ] - data2 [ 'Real Value' ]) result = pd . concat ([ result , individual_disagreements , system_disagreement ], axis = 1 ) return result","title":"Data summary generation"},{"location":"evaluation.html#evaluation-metrics","text":"The following functions apply different regression metrices onto the forecasted data. More, metrics can be added using the same template. Further regression metrices can be important from the Scikit-learn python library here . def mse_score ( df : DataFrame , plot : bool = False ) -> DataFrame : '''Calculates the mean squared error for the individual predictors and consensus algorithms. Option to plot MSE performances in descending order. Parameters: df (DataFrame): DataFrame containing individual predictors forecasts and consensus values of algorithms. plot (bool): Option to plot MSE performance chart. Returns: (DataFrame): DataFrame containing mean squared error of individual predictors forecasts and consensus values of algorithms. ''' # finding start and end index since Real Value column is in the middle end = ( list ( df . columns ) . index ( 'Real Value' )) start = ( list ( df . columns ) . index ( 'Real Value' )) + 1 y_true = df [ 'Real Value' ] name = [] mse = [] for i in range ( 0 , end ): name . append ( df . columns [ i ]) mse . append ( mean_squared_error ( y_true , df . iloc [:, i ])) for i in range ( start , df . shape [ 1 ]): name . append ( df . columns [ i ]) mse . append ( mean_squared_error ( y_true , df . iloc [:, i ])) data = { 'Algorithms' : name , 'MSE' : mse } result = pd . DataFrame ( data ) if plot == True : # plotting results if set to True to_plot = result . sort_values ( by = 'MSE' ) to_plot . plot . bar ( x = 'Algorithms' , y = 'MSE' , figsize = ( 15 , 6 )) return result def mae_score ( df : DataFrame , plot : bool = False ) -> DataFrame : '''Calculates the mean absolute error for the individual predictors and consensus algorithms. Option to plot MAE performances in descending order. Parameters: df (DataFrame): DataFrame containing individual predictors forecasts and consensus values of algorithms. plot (bool): Option to plot MAE performance chart. Returns: (DataFrame): DataFrame containing mean absolute error of individual predictors forecasts and consensus values of algorithms. ''' end = ( list ( df . columns ) . index ( 'Real Value' )) start = ( list ( df . columns ) . index ( 'Real Value' )) + 1 y_true = df [ 'Real Value' ] name = [] mae = [] for i in range ( 0 , end ): name . append ( df . columns [ i ]) mae . append ( mean_absolute_error ( y_true , df . iloc [:, i ])) for i in range ( start , df . shape [ 1 ]): name . append ( df . columns [ i ]) mae . append ( mean_absolute_error ( y_true , df . iloc [:, i ])) data = { 'Algorithms' : name , 'MAE' : mae } result = pd . DataFrame ( data ) if plot == True : to_plot = result . sort_values ( by = 'MAE' ) to_plot . plot . bar ( x = 'Algorithms' , y = 'MAE' , figsize = ( 15 , 6 )) return result def mse_log_score ( df : DataFrame , plot : bool = False ) -> DataFrame : '''Calculates the mean squared log error for the individual predictors and consensus algorithms. Option to plot MSE log performances in descending order. Parameters: df (DataFrame): DataFrame containing individual predictors forecasts and consensus values of algorithms. plot (bool): Option to plot MSE log performance chart. Returns: (DataFrame): DataFrame containing mean squared log error of individual predictors forecasts and consensus values of algorithms. ''' end = ( list ( df . columns ) . index ( 'Real Value' )) start = ( list ( df . columns ) . index ( 'Real Value' )) + 1 y_true = df [ 'Real Value' ] name = [] mse_log = [] for i in range ( 0 , end ): name . append ( df . columns [ i ]) mse_log . append ( mean_squared_log_error ( y_true , df . iloc [:, i ])) for i in range ( start , df . shape [ 1 ]): name . append ( df . columns [ i ]) mse_log . append ( mean_squared_log_error ( y_true , df . iloc [:, i ])) data = { 'Algorithms' : name , 'MSE Log' : mse_log } result = pd . DataFrame ( data ) if plot == True : to_plot = result . sort_values ( by = 'MSE Log' ) to_plot . plot . bar ( x = 'Algorithms' , y = 'MSE Log' , figsize = ( 15 , 6 )) return result","title":"Evaluation Metrics"},{"location":"evaluation.html#plotting","text":"The last part of the activate.py file plots all predictions vs the real values: def plot_performance ( data : DataFrame ): '''Plots individual predictors forecasts and consensus values of algorithms against the real values. Parameters: data (DataFrame): DataFrame containing individual predictors forecasts, consensus values and real values. ''' columns = data . columns for i in range ( len ( columns )): if columns [ i ] == 'Real Value' : continue abs_error = abs ( data [ columns [ i ]] - data [ 'Real Value' ]) # absolute error between real and predicted values (subplot) fig , ax = plt . subplots ( 2 , 1 , figsize = ( 15 , 6 )) ax [ 0 ] . plot ( data [ 'Real Value' ]) ax [ 0 ] . plot ( data [ columns [ i ]]) ax [ 0 ] . title . set_text ( columns [ i ] + ' Algorithm Error' ) ax [ 0 ] . set_ylabel ( 'Stock Price' ) ax [ 0 ] . set_xlabel ( 'Time' ) ax [ 0 ] . legend ([ 'Real Value' , 'Prediction' ], loc = 'upper right' ) ax [ 1 ] . plot ( abs_error , 'r' ) ax [ 1 ] . title . set_text ( columns [ i ] + ' Absolute Error' ) ax [ 1 ] . set_ylabel ( 'Error' ) ax [ 1 ] . set_xlabel ( 'Time' ) ax [ 1 ] . legend ([ 'Error' ], loc = 'upper right' ) plt . tight_layout ()","title":"Plotting"},{"location":"individual.html","text":".formatting { text-align: justify; } Individual predictors There are three different categories of example individual predictors included in the proof-of-concept system. The first category consists of univariate multistep Keras based predictors which are implemented in the predictorsI.py and predictorsIII.py files. The second category includes Facebook's Prophet model and the Neural Prophet model which are contained within the predictorsII.py file. The third and last category translates the univariate multistep predictors in the predictorsI.py file into multivariate multistep Keras predictors. The last category is implemented in the predictorsX.py file which is contained within the experimental directory. Simple modification example The example predictors contained within the first and third category can be used as basis for new architectures. For example, the following code is contained within the predictorsIII.py file and creates a CNN-LSTM structure. def create_cnnlstm ( self ): '''Creates CNN-LSTM hybrid model by defining all layers with activation functions, optimizer, loss function and evaluation metrics. ''' self . set_model_id ( 'CNN-LSTM' ) self . model = Sequential () self . model . add ( TimeDistributed ( Conv1D ( filters = 64 , kernel_size = 2 , activation = 'relu' ), input_shape = ( None , self . modified_back , 1 ))) self . model . add ( TimeDistributed ( Conv1D ( filters = 32 , kernel_size = 2 , activation = 'relu' ))) self . model . add ( TimeDistributed ( MaxPooling1D ( pool_size = 2 ))) self . model . add ( TimeDistributed ( Flatten ())) self . model . add ( LSTM ( 50 , activation = 'relu' , return_sequences = True )) # layer to be modified self . model . add ( LSTM ( 25 , activation = 'relu' )) self . model . add ( Dense ( self . input_y . shape [ 1 ])) self . model . compile ( optimizer = 'adam' , loss = 'mean_squared_error' , metrics = [ 'mean_squared_error' ]) A possible new architecture might be based on the CNN-LSTM structure shown in the above. For example, by substituting the first LSTM layer with a bidirectional LSTM layer a new architecture is created. def create_cnnbilstm ( self ): '''Creates CNN-Bidirectional-LSTM hybrid model by defining all layers with activation functions, optimizer, loss function and evaluation metrics. ''' self . set_model_id ( 'CNN-Bi-LSTM' ) self . model = Sequential () self . model . add ( TimeDistributed ( Conv1D ( filters = 64 , kernel_size = 2 , activation = 'relu' ), input_shape = ( None , self . modified_back , 1 ))) self . model . add ( TimeDistributed ( Conv1D ( filters = 32 , kernel_size = 2 , activation = 'relu' ))) self . model . add ( TimeDistributed ( MaxPooling1D ( pool_size = 2 ))) self . model . add ( TimeDistributed ( Flatten ())) self . model . add ( Bidirectional ( LSTM ( 50 , activation = 'relu' , return_sequences = True ))) # modified layer self . model . add ( LSTM ( 25 , activation = 'relu' )) self . model . add ( Dense ( self . input_y . shape [ 1 ])) self . model . compile ( optimizer = 'adam' , loss = 'mean_squared_error' , metrics = [ 'mean_squared_error' ])","title":"Predictors"},{"location":"individual.html#individual-predictors","text":"There are three different categories of example individual predictors included in the proof-of-concept system. The first category consists of univariate multistep Keras based predictors which are implemented in the predictorsI.py and predictorsIII.py files. The second category includes Facebook's Prophet model and the Neural Prophet model which are contained within the predictorsII.py file. The third and last category translates the univariate multistep predictors in the predictorsI.py file into multivariate multistep Keras predictors. The last category is implemented in the predictorsX.py file which is contained within the experimental directory.","title":"Individual predictors"},{"location":"individual.html#simple-modification-example","text":"The example predictors contained within the first and third category can be used as basis for new architectures. For example, the following code is contained within the predictorsIII.py file and creates a CNN-LSTM structure. def create_cnnlstm ( self ): '''Creates CNN-LSTM hybrid model by defining all layers with activation functions, optimizer, loss function and evaluation metrics. ''' self . set_model_id ( 'CNN-LSTM' ) self . model = Sequential () self . model . add ( TimeDistributed ( Conv1D ( filters = 64 , kernel_size = 2 , activation = 'relu' ), input_shape = ( None , self . modified_back , 1 ))) self . model . add ( TimeDistributed ( Conv1D ( filters = 32 , kernel_size = 2 , activation = 'relu' ))) self . model . add ( TimeDistributed ( MaxPooling1D ( pool_size = 2 ))) self . model . add ( TimeDistributed ( Flatten ())) self . model . add ( LSTM ( 50 , activation = 'relu' , return_sequences = True )) # layer to be modified self . model . add ( LSTM ( 25 , activation = 'relu' )) self . model . add ( Dense ( self . input_y . shape [ 1 ])) self . model . compile ( optimizer = 'adam' , loss = 'mean_squared_error' , metrics = [ 'mean_squared_error' ]) A possible new architecture might be based on the CNN-LSTM structure shown in the above. For example, by substituting the first LSTM layer with a bidirectional LSTM layer a new architecture is created. def create_cnnbilstm ( self ): '''Creates CNN-Bidirectional-LSTM hybrid model by defining all layers with activation functions, optimizer, loss function and evaluation metrics. ''' self . set_model_id ( 'CNN-Bi-LSTM' ) self . model = Sequential () self . model . add ( TimeDistributed ( Conv1D ( filters = 64 , kernel_size = 2 , activation = 'relu' ), input_shape = ( None , self . modified_back , 1 ))) self . model . add ( TimeDistributed ( Conv1D ( filters = 32 , kernel_size = 2 , activation = 'relu' ))) self . model . add ( TimeDistributed ( MaxPooling1D ( pool_size = 2 ))) self . model . add ( TimeDistributed ( Flatten ())) self . model . add ( Bidirectional ( LSTM ( 50 , activation = 'relu' , return_sequences = True ))) # modified layer self . model . add ( LSTM ( 25 , activation = 'relu' )) self . model . add ( Dense ( self . input_y . shape [ 1 ])) self . model . compile ( optimizer = 'adam' , loss = 'mean_squared_error' , metrics = [ 'mean_squared_error' ])","title":"Simple modification example"},{"location":"installation.html","text":".formatting { text-align: justify; } Installation IMPORTANT: The installation instruction are tested on a Windows 10 operating system. There might be alterations necessary to run the program on another operating system First download the program repository. The proof of concept program uses a Jupyter notebook as UI. The program can also be used without a Jupyter notebook by executing the main.py file. In case of executing the main.py file, a small GUI will appear after the model set-up in the file has been successfully trained. The GUI is a window containing buttons to display different statistics about the systems overall performance. However, it is recommended to use the system with a Jupyter notebook and the main.py file to demo the system. In addition, it is recommend to use Anaconda to run the Jupyter notebook and manage the necessary python libraries for this program. Anaconda can be downloaded here . After Anaconda has been downloaded and successfully installed, open the anaconda terminal/command line and create a virtual environment with the following command: conda create -n yourenvname python = 3 .8 After the environment is installed, activate it by typing: conda activate yourenvname Please proceed by installing Jupyter notebook by executing: conda install jupyter notebook Now, all dependencies for the program need to be installed. First, pip install torch v.1.6 from here . I recommend to use the CPU only version. As indicated on the official PyTorch website, the CPU version for Windows (and Linux) can be installed by executing: pip install torch == 1 .6.0+cpu torchvision == 0 .7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html Or alternatively for OSX: pip install torch == 1 .6.0 torchvision == 0 .7.0 Finally, cd into the program directory and execute: pip install -r requirements.txt This will install all other necessary dependencies. For full reference, the full_env_requirements.txt contains all dependencies installed in the anaconda environment that was used to build this prototype system.","title":"Installation"},{"location":"installation.html#installation","text":"IMPORTANT: The installation instruction are tested on a Windows 10 operating system. There might be alterations necessary to run the program on another operating system First download the program repository. The proof of concept program uses a Jupyter notebook as UI. The program can also be used without a Jupyter notebook by executing the main.py file. In case of executing the main.py file, a small GUI will appear after the model set-up in the file has been successfully trained. The GUI is a window containing buttons to display different statistics about the systems overall performance. However, it is recommended to use the system with a Jupyter notebook and the main.py file to demo the system. In addition, it is recommend to use Anaconda to run the Jupyter notebook and manage the necessary python libraries for this program. Anaconda can be downloaded here . After Anaconda has been downloaded and successfully installed, open the anaconda terminal/command line and create a virtual environment with the following command: conda create -n yourenvname python = 3 .8 After the environment is installed, activate it by typing: conda activate yourenvname Please proceed by installing Jupyter notebook by executing: conda install jupyter notebook Now, all dependencies for the program need to be installed. First, pip install torch v.1.6 from here . I recommend to use the CPU only version. As indicated on the official PyTorch website, the CPU version for Windows (and Linux) can be installed by executing: pip install torch == 1 .6.0+cpu torchvision == 0 .7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html Or alternatively for OSX: pip install torch == 1 .6.0 torchvision == 0 .7.0 Finally, cd into the program directory and execute: pip install -r requirements.txt This will install all other necessary dependencies. For full reference, the full_env_requirements.txt contains all dependencies installed in the anaconda environment that was used to build this prototype system.","title":"Installation"},{"location":"modify.html","text":".formatting { text-align: justify; } System Configuration The system was designed to be adjusted and modified in multiple ways. First, the \"tools\" directory contains the individual predictors and supports example predictors based on the Keras python library. This overall framework can be used to add further individual predictor configurations but also offers the liberty to add predictors independent of this format. In the case of diverting from this structure, it is important that the predictor returns a DataFrame containing the future predictions. Lastly, the Keras models already contained within the system can be trained and used as pre-trained models. Please find in the following examples of the pre-training process in the Pre-trained models section. The \"tools\" directory furthermore contains the dataloader which serves to import stock data. Other data can be imported by creating a similar data import solution. Second, the \"consensus\" directory contains the algorithms.py file. that build the systems final consensus/prediction value. Further, consensus algorithm solutions can be added here as well. In general, the algorithm will need to take in a DataFrame containing the different predictors forecasts and another list or DataFrame containing actual real values. Third, the directory \"system\" contains the activate.py file which brings all of the individual parts together and enables the system to run. Multiple adjustments can be made here to tailor the systems output. Fourth, the evaluation.py included within the tools directory provides the system with evaluation capabilities. The standard file contains a correlation analysis of the absolute error of all algorithms, MSE metric, MSE Log metric and MAE metric. Moreover, the evaluation.py file includes plotting functionalities. More evaluation metrics can be added if needed. Fifth, the main.py file serves to run the system from a command line. It trains all models specified in the template live and offers a GUI to display the results. activate.py The following section will break down the activate.py file in detail and suggests how possible modifications might be implemented. Imports First, all necessary libraries and other parts of the system are imported. import pandas as pd from pandas import DataFrame import sys sys . path . append ( '../' ) from consensus.algorithms import * from tools.dataloader import * from tools.predictorsI import * from tools.predictorsII import * from tools.predictorsIII import * from tools.evaluation import * Data preparation The following function is used to prepare the data into an input batch and real value batch. This function might need adjustments depending on what format other possible predictors may require. In this version, the function is able to deal with all predictors contained in predictorsI.py, predictorsII.py and predictorsIII.py. def data_prep ( df : DataFrame , input_batch_size : int , future_horizon : int ) -> [( DataFrame , DataFrame )]: '''Takes in data and splits it into an input batch for the individual predictors to perform a prediction on and the real values observed. Parameters: df (DataFrame): Whole data set to be divided into prediction batch and real values. input_batch_size (int): Length of input batch size. future_horizon (int): How many time steps are predicted into the future. Returns: [(DataFrame, DataFrame)]: Input batch dataframe and real value dataframe. ''' input_b = df [ 0 : input_batch_size ] real_value = df [ input_batch_size : input_batch_size + future_horizon ] return input_b , real_value Individual predictor live-training templates The following configurations are examples of how the system can be used with live model training. In detail, these templates train the models in real time instead of loading a pre-trained model. This variation is also used in the demo version of the system in the main.py file. def individual_predictors_template0 ( training_df : DataFrame , input_batch : DataFrame , future_horizon : int , epochs : int ) -> DataFrame : '''Handles the individual predictors by training them and feeding them the data to predict the specified future horizon. The following individual predictors are implemented: 1. CNN-LSTM 2. Bidirectional LSTM 3. CNN Parameters: training_df (DataFrame): Data on which the predictors are trained on. input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. epochs (int): Determines for how many epochs each model is trained. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = HybridUnivariatePredictor ( 2 , len ( input_batch ), future_horizon , training_df ) one . create_cnnlstm () one . fit_model ( epochs ) one . show_performance () two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) two . create_bilstm () two . fit_model ( epochs ) two . show_performance () three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) three . create_cnn () three . fit_model ( epochs ) three . show_performance () prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three ], axis = 1 ) return final_df def individual_predictors_template1 ( training_df : DataFrame , input_batch : DataFrame , future_horizon : int , epochs : int ) -> DataFrame : '''Handles the individual predictors by training them and feeding them the data to predict the specified future horizon. The following individual predictors are implemented: 1. CNN-LSTM 2. Bidirectional LSTM 3. CNN 4. MLP 5. LSTM Parameters: training_df (DataFrame): Data on which the predictors are trained on. input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. epochs (int): Determines for how many epochs each model is trained. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = HybridUnivariatePredictor ( 2 , len ( input_batch ), future_horizon , training_df ) one . create_cnnlstm () one . fit_model ( epochs ) one . show_performance () two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) two . create_bilstm () two . fit_model ( epochs ) two . show_performance () three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) three . create_cnn () three . fit_model ( epochs ) three . show_performance () four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) four . create_mlp () four . fit_model ( epochs ) four . show_performance () five = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) five . create_lstm () five . fit_model ( epochs ) five . show_performance () prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) prediction_five = five . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four , prediction_five ], axis = 1 ) return final_df The following template is a special version of the prior two. This template enables the use of the Facebook prophet and Facebook neural prophet python libraries. These models do not require a specific batch input to forecast. def individual_predictors_template2 ( training_df : DataFrame , future_horizon : int ) -> DataFrame : '''Handles the individual predictors by training them and feeding them the data to predict the specified future horizon. The following individual predictors are implemented: 1. Facebook Prophet 2. Facebook Neural Prophet Parameters: training_df (DataFrame): Data on which the predictors are trained on. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = UnivariatePredictorII ( training_df , future_horizon ) one . fit_neural_model ( 150 , 'D' ) one . show_performance_neural () two = UnivariatePredictorII ( training_df , future_horizon ) two . fit_prophet_model () two . show_performance_prophet () prediction_one = one . predict_neural () prediction_two = two . predict_prophet () final_df = pd . concat ([ prediction_one , prediction_two ], axis = 1 ) return final_df Please find in the following an example run of this predictor template: Individual predictor pre-trained templates The next templates are configured so that a pre-trained Keras model can be used to forecast. These examples use the pre-trained models saved in the \"pretrained\" directory. It is important to manually set the model id via the set_model_id() setter function. def individual_predictors_pretrained_Ford_5_2 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained Ford stock model (horizon=5) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) # manual model ID/name setting, necessary since model is pretrained and loaded from a file one . load_model ( '../pretrained/LSTM_Ford_5' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_Ford_5' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two ], axis = 1 ) return final_df def individual_predictors_pretrained_BP_30_2 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained BP stock model (horizon=30) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_BP_30' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_BP_30' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two ], axis = 1 ) return final_df def individual_predictors_pretrained_SP500_40_2 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained SP500 index model (horizon=40) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_SP500_40' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_SP500_40' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two ], axis = 1 ) return final_df def individual_predictors_pretrained_Ford_5_3 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained Ford stock model (horizon=5) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_Ford_5' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_Ford_5' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_Ford_5' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three ], axis = 1 ) return final_df def individual_predictors_pretrained_BP_30_3 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained BP stock model (horizon=30) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_BP_30' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_BP_30' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_BP_30' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three ], axis = 1 ) return final_df def individual_predictors_pretrained_SP500_40_3 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained SP500 index model (horizon=40) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_SP500_40' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_SP500_40' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_SP500_40' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three ], axis = 1 ) return final_df def individual_predictors_pretrained_Ford_5_4 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained Ford stock model (horizon=5) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_Ford_5' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_Ford_5' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_Ford_5' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_Ford_5' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four ], axis = 1 ) return final_df def individual_predictors_pretrained_BP_30_4 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained BP stock model (horizon=30) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_BP_30' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_BP_30' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_BP_30' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_BP_30' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four ], axis = 1 ) return final_df def individual_predictors_pretrained_SP500_40_4 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained SP500 index model (horizon=40) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_SP500_40' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_SP500_40' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_SP500_40' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_SP500_40' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four ], axis = 1 ) return final_df def individual_predictors_pretrained_Ford_5_5 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained Ford stock model (horizon=5) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM 5. CNN-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_Ford_5' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_Ford_5' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_Ford_5' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_Ford_5' ) five = HybridUnivariatePredictor ( sub_seq = 2 , steps_past = len ( input_batch ), steps_future = future_horizon ) five . set_model_id ( 'CNN-LSTM' ) five . load_model ( '../pretrained/CNN-LSTM_Ford_5' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) prediction_five = five . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four , prediction_five ], axis = 1 ) return final_df def individual_predictors_pretrained_BP_30_5 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained BP stock model (horizon=30) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM 5. CNN-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_BP_30' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_BP_30' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_BP_30' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_BP_30' ) five = HybridUnivariatePredictor ( sub_seq = 2 , steps_past = len ( input_batch ), steps_future = future_horizon ) five . set_model_id ( 'CNN-LSTM' ) five . load_model ( '../pretrained/CNN-LSTM_BP_30' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) prediction_five = five . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four , prediction_five ], axis = 1 ) return final_df def individual_predictors_pretrained_SP500_40_5 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained SP500 index model (horizon=40) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM 5. CNN-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_SP500_40' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_SP500_40' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_SP500_40' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_SP500_40' ) five = HybridUnivariatePredictor ( sub_seq = 2 , steps_past = len ( input_batch ), steps_future = future_horizon ) five . set_model_id ( 'CNN-LSTM' ) five . load_model ( '../pretrained/CNN-LSTM_SP500_40' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) prediction_five = five . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four , prediction_five ], axis = 1 ) return final_df System disagreement This function wraps around the system disagreement functions contained in the algorithms.py and plots the results. def system_disagreement ( df : DataFrame ): '''Plots the overall system disagreement and the individual disagreement scores of the algorithms. Parameters: df (DataFrame): Containing all individual predictors forecasts. ''' disagreement ( df ) . plot () predictor_score ( df ) . plot () System consensus value This function wraps around the consensus value creation functions contained in the algorithms.py. def consensus ( df : DataFrame , real : DataFrame ) -> DataFrame : '''Applies the following consensus algorithm to provide the final system forecast: 1. Average 2. No Memory 3. Memory 4. Focus 5. Anchor 6. Correcting 7. Correcting Memory Parameters: df (DataFrame): Forecasts of all individual predictors. real (DataFrame): The true/actual values. Returns: (DataFrame): Containing all final consensus values from all algorithms. ''' consensus = pd . DataFrame () # DataFrame that will hold all consensus values average = average_consolidation ( df ) nomemory = consolidated_predictions ( df , real ) memory = consolidated_predictions_memory ( df , real ) focus = consolidated_predictions_focused ( df , real ) anchor = consolidated_predictions_anchor ( df , real , 3.5 ) correcting = consolidated_predictions_correcting ( df , real ) correcting_mem = consolidated_predictions_memory_correcting ( df , real ) consensus [ 'Average' ] = average consensus [ 'NoMemory' ] = nomemory consensus [ 'Memory' ] = memory consensus [ 'Focus' ] = focus consensus [ 'Anchor' ] = anchor consensus [ 'Correcting' ] = correcting consensus [ 'Correcting Memory' ] = correcting_mem return consensus Correcting consensus algorithm only This is an alternative version of the prior consensus function that allows to only apply the correcting consensus value algorithm. def consensus_optimal ( df : DataFrame , real : DataFrame ) -> DataFrame : '''Applies the correcting consensus algorithm to provide the final system forecast. Parameters: df (DataFrame): Forecasts of all individual predictors. real (DataFrame): The true/actual values. Returns: (DataFrame): Containing all final consensus values from all algorithms. ''' consensus = pd . DataFrame () # DataFrame that will hold consensus values correcting = consolidated_predictions_correcting ( df , real ) consensus [ 'Correcting' ] = correcting return consensus main.py This file contains the logic of running the system from a command line. Multiple adjustments can be made to further tailor the system. Importing the system This part of the code imports the python library PySimpleGUI to generate the GUI after the models have completed the training cycle. Moreover, it imports the proof-of-concept system. import PySimpleGUI as sg import pandas as pd from tools.dataloader import * from system.activate import * System activation - Live training The next part initiates the live training process of the models defined and applies all other functions to generate the consensus value and evaluation metrics. This code should be modified to change the stock, trainings data, prediction horizon data, evaluation function, individual prediction models and consensus algorithms used. It is recommended to set-up other prediction and consensus algorithms and any other new functions within the activate.py file. def main (): '''Example main function to execute the system without a jupyter notebook as UI. ''' predict = DataLoader ( 'BP' , '2018-02-01' , '2018-05-01' ) # loading DataFrame of time-frame to be predicted predict = predict . get_adjclose () training = DataLoader ( 'BP' , '2015-01-01' , '2018-01-01' ) # loading training DataFrame to train model on training = training . get_adjclose () predict_req , real = data_prep ( predict , 20 , 30 ) # dividing data into predictor input and real data individual_predictors_forecasts = individual_predictors_template1 ( training , predict_req , 30 , 5 ) # make forecast consensus_forecasts = consensus ( individual_predictors_forecasts , real ) # create consolidation values #consensus_forecasts = consensus_optimal(individual_predictors_forecasts, real) # create consolidation value only with correcting algorithm all_forecasts = combined_frame ( individual_predictors_forecasts , consensus_forecasts , real ) prediction_error = absolute_error_analytics ( individual_predictors_forecasts , consensus_forecasts , real ) # create absolute error DataFrame The next part defines the GUI pop-up window layout: # build GUI for data visualization sg . ChangeLookAndFeel ( 'Dark' ) sg . SetOptions ( element_padding = ( 5 , 5 )) layout = [ [ sg . Text ( 'Arguing Predictors' , font = ( 'Consolas' , 10 ))], [ sg . Text ( '' * 50 )], [ sg . Frame ( 'Overall System' ,[[ sg . Button ( 'System Disagreement' , button_color = ( 'black' )), sg . Button ( 'Correlation' , button_color = ( 'black' ))]])], [ sg . Text ( '' * 70 )], [ sg . Frame ( 'Evaluation metrics' ,[[ sg . Button ( 'MSE' , button_color = ( 'black' )), sg . Button ( 'MSE Log' , button_color = ( 'black' )), sg . Button ( 'MAE' , button_color = ( 'black' ))]])], [ sg . Text ( '' * 70 )], [ sg . Frame ( 'Save to CSV' ,[[ sg . Button ( 'All Forecasts' , button_color = ( 'green' )), sg . Button ( 'MSE values' , button_color = ( 'green' )), sg . Button ( 'MSE Log values' , button_color = ( 'green' )), sg . Button ( 'MAE values' , button_color = ( 'green' ))]])], [ sg . Text ( '' * 70 )], [ sg . Frame ( 'Summary' ,[[ sg . Button ( 'Plot Performance' , button_color = ( 'black' ))]])], [ sg . Text ( '_' * 70 )], [ sg . Cancel ( button_color = ( 'red' ))]] window = sg . Window ( 'Arguing Predictors' , layout , default_element_size = ( 40 , 1 )) The code in the above generates with help of the PySimpleGUI library the following simple GUI window: Finally, the while loop in the below adds functionality to the buttons created in the prior part: while True : event , values = window . read () if event in ( sg . WIN_CLOSED , 'Cancel' ): break elif event == 'System Disagreement' : system_disagreement ( individual_predictors_forecasts ) plt . tight_layout () plt . show ( block = False ) elif event == 'Correlation' : correlation ( prediction_error , True ) plt . tight_layout () plt . show ( block = False ) elif event == 'MSE' : mse_score ( all_forecasts , True ) plt . show ( block = False ) elif event == 'MSE Log' : mse_log_score ( all_forecasts , True ) plt . show ( block = False ) elif event == 'MAE' : mae_score ( all_forecasts , True ) plt . show ( block = False ) elif event == 'All Forecasts' : all_forecasts . to_csv ( 'All_Forecasts.csv' ) # the following four buttons save the target data in csv format into the same directory where the main.py file has been executed elif event == 'MSE values' : mse_score ( all_forecasts ) . to_csv ( 'MSE.csv' ) elif event == 'MSE Log values' : mse_log_score ( all_forecasts ) . to_csv ( 'MSE_Log.csv' ) elif event == 'MAE values' : mae_score ( all_forecasts ) . to_csv ( 'MAE.csv' ) elif event == 'Plot Performance' : plot_performance ( all_forecasts ) plt . show ( block = False ) window . close () if __name__ == \"__main__\" : main ()","title":"The System"},{"location":"modify.html#system-configuration","text":"The system was designed to be adjusted and modified in multiple ways. First, the \"tools\" directory contains the individual predictors and supports example predictors based on the Keras python library. This overall framework can be used to add further individual predictor configurations but also offers the liberty to add predictors independent of this format. In the case of diverting from this structure, it is important that the predictor returns a DataFrame containing the future predictions. Lastly, the Keras models already contained within the system can be trained and used as pre-trained models. Please find in the following examples of the pre-training process in the Pre-trained models section. The \"tools\" directory furthermore contains the dataloader which serves to import stock data. Other data can be imported by creating a similar data import solution. Second, the \"consensus\" directory contains the algorithms.py file. that build the systems final consensus/prediction value. Further, consensus algorithm solutions can be added here as well. In general, the algorithm will need to take in a DataFrame containing the different predictors forecasts and another list or DataFrame containing actual real values. Third, the directory \"system\" contains the activate.py file which brings all of the individual parts together and enables the system to run. Multiple adjustments can be made here to tailor the systems output. Fourth, the evaluation.py included within the tools directory provides the system with evaluation capabilities. The standard file contains a correlation analysis of the absolute error of all algorithms, MSE metric, MSE Log metric and MAE metric. Moreover, the evaluation.py file includes plotting functionalities. More evaluation metrics can be added if needed. Fifth, the main.py file serves to run the system from a command line. It trains all models specified in the template live and offers a GUI to display the results.","title":"System Configuration"},{"location":"modify.html#activatepy","text":"The following section will break down the activate.py file in detail and suggests how possible modifications might be implemented.","title":"activate.py"},{"location":"modify.html#imports","text":"First, all necessary libraries and other parts of the system are imported. import pandas as pd from pandas import DataFrame import sys sys . path . append ( '../' ) from consensus.algorithms import * from tools.dataloader import * from tools.predictorsI import * from tools.predictorsII import * from tools.predictorsIII import * from tools.evaluation import *","title":"Imports"},{"location":"modify.html#data-preparation","text":"The following function is used to prepare the data into an input batch and real value batch. This function might need adjustments depending on what format other possible predictors may require. In this version, the function is able to deal with all predictors contained in predictorsI.py, predictorsII.py and predictorsIII.py. def data_prep ( df : DataFrame , input_batch_size : int , future_horizon : int ) -> [( DataFrame , DataFrame )]: '''Takes in data and splits it into an input batch for the individual predictors to perform a prediction on and the real values observed. Parameters: df (DataFrame): Whole data set to be divided into prediction batch and real values. input_batch_size (int): Length of input batch size. future_horizon (int): How many time steps are predicted into the future. Returns: [(DataFrame, DataFrame)]: Input batch dataframe and real value dataframe. ''' input_b = df [ 0 : input_batch_size ] real_value = df [ input_batch_size : input_batch_size + future_horizon ] return input_b , real_value","title":"Data preparation"},{"location":"modify.html#individual-predictor-live-training-templates","text":"The following configurations are examples of how the system can be used with live model training. In detail, these templates train the models in real time instead of loading a pre-trained model. This variation is also used in the demo version of the system in the main.py file. def individual_predictors_template0 ( training_df : DataFrame , input_batch : DataFrame , future_horizon : int , epochs : int ) -> DataFrame : '''Handles the individual predictors by training them and feeding them the data to predict the specified future horizon. The following individual predictors are implemented: 1. CNN-LSTM 2. Bidirectional LSTM 3. CNN Parameters: training_df (DataFrame): Data on which the predictors are trained on. input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. epochs (int): Determines for how many epochs each model is trained. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = HybridUnivariatePredictor ( 2 , len ( input_batch ), future_horizon , training_df ) one . create_cnnlstm () one . fit_model ( epochs ) one . show_performance () two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) two . create_bilstm () two . fit_model ( epochs ) two . show_performance () three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) three . create_cnn () three . fit_model ( epochs ) three . show_performance () prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three ], axis = 1 ) return final_df def individual_predictors_template1 ( training_df : DataFrame , input_batch : DataFrame , future_horizon : int , epochs : int ) -> DataFrame : '''Handles the individual predictors by training them and feeding them the data to predict the specified future horizon. The following individual predictors are implemented: 1. CNN-LSTM 2. Bidirectional LSTM 3. CNN 4. MLP 5. LSTM Parameters: training_df (DataFrame): Data on which the predictors are trained on. input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. epochs (int): Determines for how many epochs each model is trained. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = HybridUnivariatePredictor ( 2 , len ( input_batch ), future_horizon , training_df ) one . create_cnnlstm () one . fit_model ( epochs ) one . show_performance () two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) two . create_bilstm () two . fit_model ( epochs ) two . show_performance () three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) three . create_cnn () three . fit_model ( epochs ) three . show_performance () four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) four . create_mlp () four . fit_model ( epochs ) four . show_performance () five = BasicUnivariatePredictor ( len ( input_batch ), future_horizon , training_df ) five . create_lstm () five . fit_model ( epochs ) five . show_performance () prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) prediction_five = five . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four , prediction_five ], axis = 1 ) return final_df The following template is a special version of the prior two. This template enables the use of the Facebook prophet and Facebook neural prophet python libraries. These models do not require a specific batch input to forecast. def individual_predictors_template2 ( training_df : DataFrame , future_horizon : int ) -> DataFrame : '''Handles the individual predictors by training them and feeding them the data to predict the specified future horizon. The following individual predictors are implemented: 1. Facebook Prophet 2. Facebook Neural Prophet Parameters: training_df (DataFrame): Data on which the predictors are trained on. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = UnivariatePredictorII ( training_df , future_horizon ) one . fit_neural_model ( 150 , 'D' ) one . show_performance_neural () two = UnivariatePredictorII ( training_df , future_horizon ) two . fit_prophet_model () two . show_performance_prophet () prediction_one = one . predict_neural () prediction_two = two . predict_prophet () final_df = pd . concat ([ prediction_one , prediction_two ], axis = 1 ) return final_df Please find in the following an example run of this predictor template:","title":"Individual predictor live-training templates"},{"location":"modify.html#individual-predictor-pre-trained-templates","text":"The next templates are configured so that a pre-trained Keras model can be used to forecast. These examples use the pre-trained models saved in the \"pretrained\" directory. It is important to manually set the model id via the set_model_id() setter function. def individual_predictors_pretrained_Ford_5_2 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained Ford stock model (horizon=5) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) # manual model ID/name setting, necessary since model is pretrained and loaded from a file one . load_model ( '../pretrained/LSTM_Ford_5' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_Ford_5' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two ], axis = 1 ) return final_df def individual_predictors_pretrained_BP_30_2 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained BP stock model (horizon=30) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_BP_30' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_BP_30' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two ], axis = 1 ) return final_df def individual_predictors_pretrained_SP500_40_2 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained SP500 index model (horizon=40) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_SP500_40' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_SP500_40' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two ], axis = 1 ) return final_df def individual_predictors_pretrained_Ford_5_3 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained Ford stock model (horizon=5) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_Ford_5' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_Ford_5' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_Ford_5' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three ], axis = 1 ) return final_df def individual_predictors_pretrained_BP_30_3 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained BP stock model (horizon=30) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_BP_30' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_BP_30' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_BP_30' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three ], axis = 1 ) return final_df def individual_predictors_pretrained_SP500_40_3 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained SP500 index model (horizon=40) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_SP500_40' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_SP500_40' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_SP500_40' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three ], axis = 1 ) return final_df def individual_predictors_pretrained_Ford_5_4 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained Ford stock model (horizon=5) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_Ford_5' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_Ford_5' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_Ford_5' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_Ford_5' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four ], axis = 1 ) return final_df def individual_predictors_pretrained_BP_30_4 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained BP stock model (horizon=30) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_BP_30' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_BP_30' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_BP_30' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_BP_30' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four ], axis = 1 ) return final_df def individual_predictors_pretrained_SP500_40_4 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained SP500 index model (horizon=40) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_SP500_40' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_SP500_40' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_SP500_40' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_SP500_40' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four ], axis = 1 ) return final_df def individual_predictors_pretrained_Ford_5_5 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained Ford stock model (horizon=5) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM 5. CNN-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_Ford_5' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_Ford_5' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_Ford_5' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_Ford_5' ) five = HybridUnivariatePredictor ( sub_seq = 2 , steps_past = len ( input_batch ), steps_future = future_horizon ) five . set_model_id ( 'CNN-LSTM' ) five . load_model ( '../pretrained/CNN-LSTM_Ford_5' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) prediction_five = five . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four , prediction_five ], axis = 1 ) return final_df def individual_predictors_pretrained_BP_30_5 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained BP stock model (horizon=30) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM 5. CNN-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_BP_30' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_BP_30' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_BP_30' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_BP_30' ) five = HybridUnivariatePredictor ( sub_seq = 2 , steps_past = len ( input_batch ), steps_future = future_horizon ) five . set_model_id ( 'CNN-LSTM' ) five . load_model ( '../pretrained/CNN-LSTM_BP_30' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) prediction_five = five . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four , prediction_five ], axis = 1 ) return final_df def individual_predictors_pretrained_SP500_40_5 ( input_batch : DataFrame , future_horizon : int ) -> DataFrame : '''Loads pretrained SP500 index model (horizon=40) and predicts based on the given input batch. The following individual predictors are implemented: 1. LSTM 2. CNN 3. MLP 4. Bidirectional-LSTM 5. CNN-LSTM Parameters: input_batch (DataFrame): Data which is fed to predictors to predict future values. future_horizon (int): Length of how far into the future the predictors will predict. Returns: (DataFrame): Containing all predictions from all individual predictors. ''' one = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) one . set_model_id ( 'LSTM' ) one . load_model ( '../pretrained/LSTM_SP500_40' ) two = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) two . set_model_id ( 'CNN' ) two . load_model ( '../pretrained/CNN_SP500_40' ) three = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) three . set_model_id ( 'MLP' ) three . load_model ( '../pretrained/MLP_SP500_40' ) four = BasicUnivariatePredictor ( len ( input_batch ), future_horizon ) four . set_model_id ( 'BI-LSTM' ) four . load_model ( '../pretrained/BI-LSTM_SP500_40' ) five = HybridUnivariatePredictor ( sub_seq = 2 , steps_past = len ( input_batch ), steps_future = future_horizon ) five . set_model_id ( 'CNN-LSTM' ) five . load_model ( '../pretrained/CNN-LSTM_SP500_40' ) prediction_one = one . predict ( input_batch ) prediction_two = two . predict ( input_batch ) prediction_three = three . predict ( input_batch ) prediction_four = four . predict ( input_batch ) prediction_five = five . predict ( input_batch ) final_df = pd . concat ([ prediction_one , prediction_two , prediction_three , prediction_four , prediction_five ], axis = 1 ) return final_df","title":"Individual predictor pre-trained templates"},{"location":"modify.html#system-disagreement","text":"This function wraps around the system disagreement functions contained in the algorithms.py and plots the results. def system_disagreement ( df : DataFrame ): '''Plots the overall system disagreement and the individual disagreement scores of the algorithms. Parameters: df (DataFrame): Containing all individual predictors forecasts. ''' disagreement ( df ) . plot () predictor_score ( df ) . plot ()","title":"System disagreement"},{"location":"modify.html#system-consensus-value","text":"This function wraps around the consensus value creation functions contained in the algorithms.py. def consensus ( df : DataFrame , real : DataFrame ) -> DataFrame : '''Applies the following consensus algorithm to provide the final system forecast: 1. Average 2. No Memory 3. Memory 4. Focus 5. Anchor 6. Correcting 7. Correcting Memory Parameters: df (DataFrame): Forecasts of all individual predictors. real (DataFrame): The true/actual values. Returns: (DataFrame): Containing all final consensus values from all algorithms. ''' consensus = pd . DataFrame () # DataFrame that will hold all consensus values average = average_consolidation ( df ) nomemory = consolidated_predictions ( df , real ) memory = consolidated_predictions_memory ( df , real ) focus = consolidated_predictions_focused ( df , real ) anchor = consolidated_predictions_anchor ( df , real , 3.5 ) correcting = consolidated_predictions_correcting ( df , real ) correcting_mem = consolidated_predictions_memory_correcting ( df , real ) consensus [ 'Average' ] = average consensus [ 'NoMemory' ] = nomemory consensus [ 'Memory' ] = memory consensus [ 'Focus' ] = focus consensus [ 'Anchor' ] = anchor consensus [ 'Correcting' ] = correcting consensus [ 'Correcting Memory' ] = correcting_mem return consensus","title":"System consensus value"},{"location":"modify.html#correcting-consensus-algorithm-only","text":"This is an alternative version of the prior consensus function that allows to only apply the correcting consensus value algorithm. def consensus_optimal ( df : DataFrame , real : DataFrame ) -> DataFrame : '''Applies the correcting consensus algorithm to provide the final system forecast. Parameters: df (DataFrame): Forecasts of all individual predictors. real (DataFrame): The true/actual values. Returns: (DataFrame): Containing all final consensus values from all algorithms. ''' consensus = pd . DataFrame () # DataFrame that will hold consensus values correcting = consolidated_predictions_correcting ( df , real ) consensus [ 'Correcting' ] = correcting return consensus","title":"Correcting consensus algorithm only"},{"location":"modify.html#mainpy","text":"This file contains the logic of running the system from a command line. Multiple adjustments can be made to further tailor the system.","title":"main.py"},{"location":"modify.html#importing-the-system","text":"This part of the code imports the python library PySimpleGUI to generate the GUI after the models have completed the training cycle. Moreover, it imports the proof-of-concept system. import PySimpleGUI as sg import pandas as pd from tools.dataloader import * from system.activate import *","title":"Importing the system"},{"location":"modify.html#system-activation-live-training","text":"The next part initiates the live training process of the models defined and applies all other functions to generate the consensus value and evaluation metrics. This code should be modified to change the stock, trainings data, prediction horizon data, evaluation function, individual prediction models and consensus algorithms used. It is recommended to set-up other prediction and consensus algorithms and any other new functions within the activate.py file. def main (): '''Example main function to execute the system without a jupyter notebook as UI. ''' predict = DataLoader ( 'BP' , '2018-02-01' , '2018-05-01' ) # loading DataFrame of time-frame to be predicted predict = predict . get_adjclose () training = DataLoader ( 'BP' , '2015-01-01' , '2018-01-01' ) # loading training DataFrame to train model on training = training . get_adjclose () predict_req , real = data_prep ( predict , 20 , 30 ) # dividing data into predictor input and real data individual_predictors_forecasts = individual_predictors_template1 ( training , predict_req , 30 , 5 ) # make forecast consensus_forecasts = consensus ( individual_predictors_forecasts , real ) # create consolidation values #consensus_forecasts = consensus_optimal(individual_predictors_forecasts, real) # create consolidation value only with correcting algorithm all_forecasts = combined_frame ( individual_predictors_forecasts , consensus_forecasts , real ) prediction_error = absolute_error_analytics ( individual_predictors_forecasts , consensus_forecasts , real ) # create absolute error DataFrame The next part defines the GUI pop-up window layout: # build GUI for data visualization sg . ChangeLookAndFeel ( 'Dark' ) sg . SetOptions ( element_padding = ( 5 , 5 )) layout = [ [ sg . Text ( 'Arguing Predictors' , font = ( 'Consolas' , 10 ))], [ sg . Text ( '' * 50 )], [ sg . Frame ( 'Overall System' ,[[ sg . Button ( 'System Disagreement' , button_color = ( 'black' )), sg . Button ( 'Correlation' , button_color = ( 'black' ))]])], [ sg . Text ( '' * 70 )], [ sg . Frame ( 'Evaluation metrics' ,[[ sg . Button ( 'MSE' , button_color = ( 'black' )), sg . Button ( 'MSE Log' , button_color = ( 'black' )), sg . Button ( 'MAE' , button_color = ( 'black' ))]])], [ sg . Text ( '' * 70 )], [ sg . Frame ( 'Save to CSV' ,[[ sg . Button ( 'All Forecasts' , button_color = ( 'green' )), sg . Button ( 'MSE values' , button_color = ( 'green' )), sg . Button ( 'MSE Log values' , button_color = ( 'green' )), sg . Button ( 'MAE values' , button_color = ( 'green' ))]])], [ sg . Text ( '' * 70 )], [ sg . Frame ( 'Summary' ,[[ sg . Button ( 'Plot Performance' , button_color = ( 'black' ))]])], [ sg . Text ( '_' * 70 )], [ sg . Cancel ( button_color = ( 'red' ))]] window = sg . Window ( 'Arguing Predictors' , layout , default_element_size = ( 40 , 1 )) The code in the above generates with help of the PySimpleGUI library the following simple GUI window: Finally, the while loop in the below adds functionality to the buttons created in the prior part: while True : event , values = window . read () if event in ( sg . WIN_CLOSED , 'Cancel' ): break elif event == 'System Disagreement' : system_disagreement ( individual_predictors_forecasts ) plt . tight_layout () plt . show ( block = False ) elif event == 'Correlation' : correlation ( prediction_error , True ) plt . tight_layout () plt . show ( block = False ) elif event == 'MSE' : mse_score ( all_forecasts , True ) plt . show ( block = False ) elif event == 'MSE Log' : mse_log_score ( all_forecasts , True ) plt . show ( block = False ) elif event == 'MAE' : mae_score ( all_forecasts , True ) plt . show ( block = False ) elif event == 'All Forecasts' : all_forecasts . to_csv ( 'All_Forecasts.csv' ) # the following four buttons save the target data in csv format into the same directory where the main.py file has been executed elif event == 'MSE values' : mse_score ( all_forecasts ) . to_csv ( 'MSE.csv' ) elif event == 'MSE Log values' : mse_log_score ( all_forecasts ) . to_csv ( 'MSE_Log.csv' ) elif event == 'MAE values' : mae_score ( all_forecasts ) . to_csv ( 'MAE.csv' ) elif event == 'Plot Performance' : plot_performance ( all_forecasts ) plt . show ( block = False ) window . close () if __name__ == \"__main__\" : main ()","title":"System activation - Live training"},{"location":"pre-trained_models.html","text":".formatting { text-align: justify; } Pre-trained models In the following you can find the training processes of all pre-trained individual predictors. Horizon 5 The first dataset used is the stock price of Ford Motor Company (F). Prices are in USD and listed on NYSE - Nasdaq. The data is extracted via the Yahoo Finance API accessed via the pandas data reader function. The adjusting closing price was used to train the following predictors. Link to the data. The data the model was trained on is the historical adjusted close stock price of Ford Motor Company, ranging from 1st of January 2010 to the 1st of January 2018. The resulting pre-trained models are: BI-LSTM_Ford_5 CNN-LSTM_Ford_5 CNN_Ford_5 LSTM_Ford_5 MLP_Ford_5 Horizon 30 The second dataset used is the stock price of BP p.l.c. (BP). Prices are in USD and listed on NYSE - Nasdaq. The data is extracted via the Yahoo Finance API accessed via the pandas data reader function. The adjusting closing price was used to train the following predictors. Link to the data. The data the model was trained on is the historical adjusted close stock price of Ford BP, ranging from 1st of January 2010 to the 1st of January 2018. The resulting pre-trained models are: BI-LSTM_BP_30 CNN-LSTM_BP_30 CNN_BP_30 LSTM_BP_30 MLP_BP_30 Horizon 40 The third dataset used is the S&P 500 (^GSPC). Prices are in USD and listed on SNP. The data is extracted via the Yahoo Finance API accessed via the pandas data reader function. The adjusting closing price was used to train the following predictors. Link to the data. The data the model was trained on is the historical adjusted close stock price of the S&P500 index, ranging from 1st of January 2010 to the 1st of January 2018. The resulting pre-trained models are: BI-LSTM_SP500_40 CNN-LSTM_SP500_40 CNN_SP500_40 LSTM_SP500_40 MLP_SP500_40","title":"Pre-Trained Models"},{"location":"pre-trained_models.html#pre-trained-models","text":"In the following you can find the training processes of all pre-trained individual predictors.","title":"Pre-trained models"},{"location":"pre-trained_models.html#horizon-5","text":"The first dataset used is the stock price of Ford Motor Company (F). Prices are in USD and listed on NYSE - Nasdaq. The data is extracted via the Yahoo Finance API accessed via the pandas data reader function. The adjusting closing price was used to train the following predictors. Link to the data. The data the model was trained on is the historical adjusted close stock price of Ford Motor Company, ranging from 1st of January 2010 to the 1st of January 2018. The resulting pre-trained models are: BI-LSTM_Ford_5 CNN-LSTM_Ford_5 CNN_Ford_5 LSTM_Ford_5 MLP_Ford_5","title":"Horizon 5"},{"location":"pre-trained_models.html#horizon-30","text":"The second dataset used is the stock price of BP p.l.c. (BP). Prices are in USD and listed on NYSE - Nasdaq. The data is extracted via the Yahoo Finance API accessed via the pandas data reader function. The adjusting closing price was used to train the following predictors. Link to the data. The data the model was trained on is the historical adjusted close stock price of Ford BP, ranging from 1st of January 2010 to the 1st of January 2018. The resulting pre-trained models are: BI-LSTM_BP_30 CNN-LSTM_BP_30 CNN_BP_30 LSTM_BP_30 MLP_BP_30","title":"Horizon 30"},{"location":"pre-trained_models.html#horizon-40","text":"The third dataset used is the S&P 500 (^GSPC). Prices are in USD and listed on SNP. The data is extracted via the Yahoo Finance API accessed via the pandas data reader function. The adjusting closing price was used to train the following predictors. Link to the data. The data the model was trained on is the historical adjusted close stock price of the S&P500 index, ranging from 1st of January 2010 to the 1st of January 2018. The resulting pre-trained models are: BI-LSTM_SP500_40 CNN-LSTM_SP500_40 CNN_SP500_40 LSTM_SP500_40 MLP_SP500_40","title":"Horizon 40"},{"location":"usage.html","text":".formatting { text-align: justify; } Starting the program Jupyter Notebook Open up an anaconda terminal/command line and activate your environment. Now open a Jupyter notebook by executing: jupyter notebook Finally, locate the downloaded repository and open up the System.ipynb contained in the notebook folder. The following is an example of a successful System.ipynb run: main.py script Alternatively, to run the program via the main.py file (make sure to be in the directory where the main.py file is located): python main.py Depending on what individual predictor configuration is used, training of the model begins and after each completed model training cycle test and validation metrics are graphically shown. Each appearing window containing plots/graphics need to be closed manually before the program can proceed running (close pop-up windows by clicking on the upper right red corner \"x\" button). After all models in the configuration have been trained, the following GUI will appear: The following shows a full test run of the main.py: This GUI enables the user to explore the systems consensus predictions and performances in detail.","title":"Start"},{"location":"usage.html#starting-the-program","text":"","title":"Starting the program"},{"location":"usage.html#jupyter-notebook","text":"Open up an anaconda terminal/command line and activate your environment. Now open a Jupyter notebook by executing: jupyter notebook Finally, locate the downloaded repository and open up the System.ipynb contained in the notebook folder. The following is an example of a successful System.ipynb run:","title":"Jupyter Notebook"},{"location":"usage.html#mainpy-script","text":"Alternatively, to run the program via the main.py file (make sure to be in the directory where the main.py file is located): python main.py Depending on what individual predictor configuration is used, training of the model begins and after each completed model training cycle test and validation metrics are graphically shown. Each appearing window containing plots/graphics need to be closed manually before the program can proceed running (close pop-up windows by clicking on the upper right red corner \"x\" button). After all models in the configuration have been trained, the following GUI will appear: The following shows a full test run of the main.py: This GUI enables the user to explore the systems consensus predictions and performances in detail.","title":"main.py script"}]}